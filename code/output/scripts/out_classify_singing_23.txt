Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/esling.41289111.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already up-to-date: pip in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (19.1.1)
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting scipy (from -r requirements.txt (line 1))
Collecting torch_gpu (from -r requirements.txt (line 2))
Collecting torchvision (from -r requirements.txt (line 3))
Collecting tqdm (from -r requirements.txt (line 4))
Collecting numpy (from -r requirements.txt (line 5))
Collecting matplotlib (from -r requirements.txt (line 6))
Collecting tensorflow_gpu (from -r requirements.txt (line 7))
Collecting pandas (from -r requirements.txt (line 8))
Collecting mpmath (from -r requirements.txt (line 9))
Collecting networkx (from -r requirements.txt (line 10))
Collecting natsort (from -r requirements.txt (line 11))
Collecting joblib (from -r requirements.txt (line 12))
Collecting scikit_learn (from -r requirements.txt (line 13))
Collecting cffi (from -r requirements.txt (line 14))
Collecting pycparser (from -r requirements.txt (line 15))
Collecting audioread (from -r requirements.txt (line 16))
Collecting decorator (from -r requirements.txt (line 17))
Collecting six (from -r requirements.txt (line 18))
Collecting llvmlite (from -r requirements.txt (line 19))
Collecting numba (from -r requirements.txt (line 20))
Collecting imageio (from -r requirements.txt (line 21))
Collecting torch (from torchvision->-r requirements.txt (line 3))
Collecting pillow-simd>=4.1.1 (from torchvision->-r requirements.txt (line 3))
Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 6))
Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting kiwisolver>=1.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting python-dateutil>=2.1 (from matplotlib->-r requirements.txt (line 6))
Collecting astor>=0.6.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-preprocessing>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting absl-py>=0.7.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting wrapt>=1.11.1 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting protobuf>=3.8.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting gast==0.2.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting termcolor>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting grpcio>=1.8.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Requirement already satisfied: wheel>=0.26; python_version >= "3" in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from tensorflow_gpu->-r requirements.txt (line 7)) (0.33.4)
Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-pasta>=0.1.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting opt-einsum>=2.3.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-applications>=1.0.8 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting pytz>=2017.2 (from pandas->-r requirements.txt (line 8))
Requirement already satisfied: setuptools in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from numba->-r requirements.txt (line 20)) (41.0.1)
Collecting pillow (from imageio->-r requirements.txt (line 21))
Collecting future (from torch->torchvision->-r requirements.txt (line 3))
Collecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests<3,>=2.21.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting h5py (from keras-applications>=1.0.8->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Installing collected packages: numpy, scipy, torch-gpu, six, future, torch, pillow-simd, torchvision, tqdm, cycler, pyparsing, kiwisolver, python-dateutil, matplotlib, astor, keras-preprocessing, absl-py, wrapt, tensorflow-estimator, protobuf, gast, termcolor, grpcio, werkzeug, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, oauthlib, idna, urllib3, chardet, certifi, requests, requests-oauthlib, google-auth-oauthlib, markdown, tensorboard, google-pasta, opt-einsum, h5py, keras-applications, tensorflow-gpu, pytz, pandas, mpmath, decorator, networkx, natsort, joblib, scikit-learn, pycparser, cffi, audioread, llvmlite, numba, pillow, imageio
Successfully installed absl-py-0.7.1 astor-0.8.1 audioread-2.1.6 cachetools-3.1.1 certifi-2020.4.5.1 cffi-1.13.2 chardet-3.0.4 cycler-0.10.0 decorator-4.4.2 future-0.17.1 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 idna-2.9 imageio-2.8.0 joblib-0.14.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 kiwisolver-1.1.0 llvmlite-0.31.0 markdown-3.2 matplotlib-3.2.1 mpmath-1.1.0 natsort-5.3.3 networkx-2.4 numba-0.48.0 numpy-1.18.1 oauthlib-3.1.0 opt-einsum-2.3.2 pandas-1.0.3 pillow-7.0.0 pillow-simd-7.0.0.post3 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 rsa-4.0 scikit-learn-0.22.1 scipy-1.4.1 six-1.14.0 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0 termcolor-1.1.0 torch-1.5.0 torch-gpu-1.0.0 torchvision-0.5.0 tqdm-4.40.2 urllib3-1.25.8 werkzeug-1.0.1 wrapt-1.11.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/nnAudio-0.1.0-py3-none-any.whl
Installing collected packages: nnAudio
Successfully installed nnAudio-0.1.0
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/SoundFile-0.10.3.post1-py2.py3-none-any.whl
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from SoundFile==0.10.3.post1) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from cffi>=1.0->SoundFile==0.10.3.post1) (2.20)
Installing collected packages: SoundFile
Successfully installed SoundFile-0.10.3.post1
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/resampy-0.2.2.tar.gz
Requirement already satisfied: numpy>=1.10 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.18.1)
Requirement already satisfied: scipy>=0.13 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.4.1)
Requirement already satisfied: numba>=0.32 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (0.48.0)
Requirement already satisfied: six>=1.3 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.14.0)
Requirement already satisfied: setuptools in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (41.0.1)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (0.31.0)
Building wheels for collected packages: resampy
  Building wheel for resampy (setup.py): started
  Building wheel for resampy (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/7f/a4/f3/4443d9c0e651405d78bca2bc790f21cb3914c168761d6ce287
Successfully built resampy
Installing collected packages: resampy
Successfully installed resampy-0.2.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/librosa-0.7.2.tar.gz
Requirement already satisfied: audioread>=2.0.0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (2.1.6)
Requirement already satisfied: numpy>=1.15.0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.18.1)
Requirement already satisfied: scipy>=1.0.0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.4.1)
Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.22.1)
Requirement already satisfied: joblib>=0.12 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.14.1)
Requirement already satisfied: decorator>=3.0.0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (4.4.2)
Requirement already satisfied: six>=1.3 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.14.0)
Requirement already satisfied: resampy>=0.2.2 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.2.2)
Requirement already satisfied: numba>=0.43.0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.48.0)
Requirement already satisfied: soundfile>=0.9.0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.10.3.post1)
Requirement already satisfied: setuptools in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (41.0.1)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)
Building wheels for collected packages: librosa
  Building wheel for librosa (setup.py): started
  Building wheel for librosa (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/5d/2c/70/9fd1f14d034354cd1109b858bb14d27d56a04a887581ff018b
Successfully built librosa
Installing collected packages: librosa
Successfully installed librosa-0.7.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/lmdb-0.98.tar.gz
Building wheels for collected packages: lmdb
  Building wheel for lmdb (setup.py): started
  Building wheel for lmdb (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/46/8c/ac/27ff74457451e040aa411ff52d641111b0a2481c9f8d31ca95
Successfully built lmdb
Installing collected packages: lmdb
Successfully installed lmdb-0.98
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/mir_eval-0.6.tar.gz
Requirement already satisfied: numpy>=1.7.0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (1.18.1)
Requirement already satisfied: scipy>=1.0.0 in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (1.4.1)
Requirement already satisfied: future in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (0.17.1)
Requirement already satisfied: six in /localscratch/esling.41289111.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (1.14.0)
Building wheels for collected packages: mir-eval
  Building wheel for mir-eval (setup.py): started
  Building wheel for mir-eval (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/d1/c4/fe/5455addf1ef19661b1d6285877644eefd17d5aa49a196aa983
Successfully built mir-eval
Installing collected packages: mir-eval
Successfully installed mir-eval-0.6
2020-04-29 05:01:05.797263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-04-29 05:01:06.164238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
*******
Run info.
Optimization will be on cuda.
Model is singing_classify_cnn_xavier_trimming_info_target_rewind_global_0.
*******
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9421]
[Starting training]
Epoch 0 	 0.758042 	 0.692096 	 0.676287
Epoch 10 	 0.326631 	 0.357537 	 0.230331
Epoch 20 	 0.143382 	 0.211397 	 0.089246
Epoch 30 	 0.091337 	 0.176930 	 0.053125
Epoch 40 	 0.065947 	 0.164982 	 0.042647
Epoch 50 	 0.044118 	 0.146599 	 0.032904
Epoch 60 	 0.031480 	 0.147059 	 0.031985
Epoch 70 	 0.019991 	 0.151195 	 0.031250
Epoch 80 	 0.014706 	 0.153493 	 0.031434
[Model stopped early]
Train loss       : 0.014361
Best valid loss  : 0.146599
Best test loss   : 0.032904
Pruning          : 1.00
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,225,214
--------------------------------
Total memory      : 8.56 MB
Total Flops       : 663.23 MFlops
Total Mem (Read)  : 11.6 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.1808]
[Starting training]
Epoch 0 	 0.055951 	 0.147518 	 0.031618
Epoch 10 	 0.046415 	 0.149357 	 0.030882
Epoch 20 	 0.037684 	 0.152574 	 0.032353
Epoch 30 	 0.031939 	 0.142923 	 0.029228
Epoch 40 	 0.018382 	 0.144301 	 0.029228
Epoch 50 	 0.014476 	 0.146599 	 0.029779
Epoch 60 	 0.014246 	 0.146140 	 0.029596
Epoch 70 	 0.012178 	 0.142004 	 0.028676
Epoch 80 	 0.007927 	 0.143842 	 0.029044
[Model stopped early]
Train loss       : 0.008387
Best valid loss  : 0.139246
Best test loss   : 0.028125
Pruning          : 0.75
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,149,369
--------------------------------
Total memory      : 8.56 MB
Total Flops       : 663.16 MFlops
Total Mem (Read)  : 11.31 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.7296]
[Starting training]
Epoch 0 	 0.099380 	 0.146140 	 0.037408
Epoch 10 	 0.047105 	 0.139706 	 0.030699
Epoch 20 	 0.039292 	 0.148438 	 0.030699
Epoch 30 	 0.025276 	 0.147518 	 0.030147
Epoch 40 	 0.018267 	 0.144301 	 0.029412
[Model stopped early]
Train loss       : 0.015970
Best valid loss  : 0.139706
Best test loss   : 0.030699
Pruning          : 0.56
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,115,887
--------------------------------
Total memory      : 8.56 MB
Total Flops       : 663.12 MFlops
Total Mem (Read)  : 11.18 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.4130]
[Starting training]
Epoch 0 	 0.164062 	 0.163603 	 0.057169
Epoch 10 	 0.060662 	 0.147518 	 0.034191
Epoch 20 	 0.047564 	 0.139246 	 0.028493
Epoch 30 	 0.042969 	 0.143842 	 0.029779
Epoch 40 	 0.035386 	 0.143382 	 0.030147
Epoch 50 	 0.019072 	 0.137868 	 0.028125
Epoch 60 	 0.013557 	 0.143842 	 0.029228
[Model stopped early]
Train loss       : 0.013557
Best valid loss  : 0.130515
Best test loss   : 0.026838
Pruning          : 0.42
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,096,949
--------------------------------
Total memory      : 8.55 MB
Total Flops       : 663.11 MFlops
Total Mem (Read)  : 11.1 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.5246]
[Starting training]
Epoch 0 	 0.283318 	 0.235754 	 0.133272
Epoch 10 	 0.075597 	 0.158088 	 0.041912
Epoch 20 	 0.054917 	 0.149816 	 0.033824
Epoch 30 	 0.031824 	 0.144761 	 0.030147
Epoch 40 	 0.022978 	 0.143382 	 0.029412
[Model stopped early]
Train loss       : 0.022978
Best valid loss  : 0.139246
Best test loss   : 0.033364
Pruning          : 0.32
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,088,899
--------------------------------
Total memory      : 8.55 MB
Total Flops       : 663.1 MFlops
Total Mem (Read)  : 11.07 MB
Total Mem (Write) : 6.41 MB
[Supermasks testing]
[Untrained loss : 0.4407]
[Starting training]
Epoch 0 	 0.392808 	 0.404871 	 0.329504
Epoch 10 	 0.098690 	 0.174173 	 0.068934
Epoch 20 	 0.065142 	 0.145680 	 0.033548
Epoch 30 	 0.056411 	 0.144301 	 0.032721
Epoch 40 	 0.038833 	 0.139706 	 0.029228
Epoch 50 	 0.034007 	 0.140625 	 0.028493
Epoch 60 	 0.022289 	 0.141085 	 0.029412
Epoch 70 	 0.021255 	 0.141544 	 0.028860
[Model stopped early]
Train loss       : 0.021255
Best valid loss  : 0.137868
Best test loss   : 0.029412
Pruning          : 0.24
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,017,645
--------------------------------
Total memory      : 8.05 MB
Total Flops       : 621.67 MFlops
Total Mem (Read)  : 10.42 MB
Total Mem (Write) : 6.04 MB
[Supermasks testing]
[Untrained loss : 0.6506]
[Starting training]
Epoch 0 	 0.501264 	 0.435662 	 0.356434
Epoch 10 	 0.217027 	 0.253676 	 0.163787
Epoch 20 	 0.145221 	 0.182904 	 0.071691
Epoch 30 	 0.118336 	 0.164982 	 0.052941
Epoch 40 	 0.101907 	 0.156710 	 0.048346
Epoch 50 	 0.087316 	 0.157169 	 0.047794
Epoch 60 	 0.074219 	 0.153493 	 0.046140
Epoch 70 	 0.058249 	 0.150735 	 0.042463
Epoch 80 	 0.056411 	 0.144761 	 0.039522
Epoch 90 	 0.052505 	 0.148438 	 0.038419
Epoch 100 	 0.046071 	 0.142004 	 0.033640
Epoch 110 	 0.042509 	 0.137868 	 0.031250
Epoch 120 	 0.040556 	 0.140625 	 0.030699
Epoch 130 	 0.038028 	 0.142463 	 0.031066
Epoch 140 	 0.034007 	 0.139246 	 0.030147
Epoch 150 	 0.032514 	 0.139246 	 0.029779
Train loss       : 0.034122
Best valid loss  : 0.135570
Best test loss   : 0.029044
Pruning          : 0.18
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 816,478
--------------------------------
Total memory      : 6.54 MB
Total Flops       : 497.42 MFlops
Total Mem (Read)  : 8.52 MB
Total Mem (Write) : 4.9 MB
[Supermasks testing]
[Untrained loss : 0.9083]
[Starting training]
Epoch 0 	 0.765625 	 0.736213 	 0.701471
Epoch 10 	 0.397633 	 0.362132 	 0.289614
Epoch 20 	 0.279756 	 0.270680 	 0.180607
Epoch 30 	 0.239545 	 0.266085 	 0.176654
Epoch 40 	 0.216108 	 0.263787 	 0.175551
Epoch 50 	 0.202206 	 0.244485 	 0.159191
Epoch 60 	 0.191291 	 0.231158 	 0.134926
Epoch 70 	 0.169807 	 0.214614 	 0.112684
Epoch 80 	 0.164982 	 0.215993 	 0.106066
Epoch 90 	 0.149586 	 0.182445 	 0.074081
Epoch 100 	 0.129710 	 0.179228 	 0.064890
Epoch 110 	 0.122243 	 0.166820 	 0.057353
Epoch 120 	 0.122702 	 0.194853 	 0.079412
Epoch 130 	 0.111788 	 0.164982 	 0.045221
Epoch 140 	 0.102826 	 0.169577 	 0.051379
Epoch 150 	 0.097312 	 0.159926 	 0.043566
Train loss       : 0.080538
Best valid loss  : 0.153952
Best test loss   : 0.038879
Pruning          : 0.13
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 484,333
--------------------------------
Total memory      : 4.13 MB
Total Flops       : 293.23 MFlops
Total Mem (Read)  : 5.45 MB
Total Mem (Write) : 3.1 MB
[Supermasks testing]
[Untrained loss : 0.9046]
[Starting training]
Epoch 0 	 0.903378 	 0.909007 	 0.909375
Epoch 10 	 0.542624 	 0.455882 	 0.377941
Epoch 20 	 0.477252 	 0.438879 	 0.386581
Epoch 30 	 0.432330 	 0.443474 	 0.381801
Epoch 40 	 0.414407 	 0.401195 	 0.342096
Epoch 50 	 0.396369 	 0.342831 	 0.269301
Epoch 60 	 0.354320 	 0.327206 	 0.237132
Epoch 70 	 0.329159 	 0.303768 	 0.210754
Epoch 80 	 0.318589 	 0.298254 	 0.198529
Epoch 90 	 0.309168 	 0.276654 	 0.169118
Epoch 100 	 0.301126 	 0.271599 	 0.157537
Epoch 110 	 0.291360 	 0.259191 	 0.154963
Epoch 120 	 0.280331 	 0.253676 	 0.152941
Epoch 130 	 0.286765 	 0.257353 	 0.156801
Epoch 140 	 0.266774 	 0.259191 	 0.153493
Epoch 150 	 0.256204 	 0.244485 	 0.139706
Train loss       : 0.259881
Best valid loss  : 0.233915
Best test loss   : 0.135110
Pruning          : 0.10
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 259,381
--------------------------------
Total memory      : 2.99 MB
Total Flops       : 166.56 MFlops
Total Mem (Read)  : 3.74 MB
Total Mem (Write) : 2.24 MB
[Supermasks testing]
[Untrained loss : 0.9108]
[Starting training]
Epoch 0 	 0.907973 	 0.910386 	 0.911581
Epoch 10 	 0.588006 	 0.575827 	 0.509191
Epoch 20 	 0.522059 	 0.465993 	 0.406066
Epoch 30 	 0.471048 	 0.441636 	 0.387316
Epoch 40 	 0.454619 	 0.446232 	 0.391360
Epoch 50 	 0.447266 	 0.435662 	 0.386581
Epoch 60 	 0.430722 	 0.435202 	 0.377757
Epoch 70 	 0.431066 	 0.430607 	 0.374081
Epoch 80 	 0.416131 	 0.415901 	 0.344669
Epoch 90 	 0.407399 	 0.409007 	 0.333456
Epoch 100 	 0.406824 	 0.401654 	 0.329044
Epoch 110 	 0.396714 	 0.389706 	 0.311765
Epoch 120 	 0.390051 	 0.388327 	 0.305882
Epoch 130 	 0.386144 	 0.375460 	 0.299449
Epoch 140 	 0.382238 	 0.372702 	 0.298897
Epoch 150 	 0.381549 	 0.375460 	 0.299816
Train loss       : 0.384421
Best valid loss  : 0.363971
Best test loss   : 0.288603
Pruning          : 0.08
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 118,400
--------------------------------
Total memory      : 1.57 MB
Total Flops       : 74.31 MFlops
Total Mem (Read)  : 2.14 MB
Total Mem (Write) : 1.18 MB
[Supermasks testing]
[Untrained loss : 0.9105]
[Starting training]
Epoch 0 	 0.906250 	 0.909926 	 0.911581
Epoch 10 	 0.852022 	 0.874540 	 0.858456
Epoch 20 	 0.800207 	 0.766085 	 0.766176
Epoch 30 	 0.668888 	 0.646599 	 0.645772
Epoch 40 	 0.656135 	 0.647518 	 0.644669
Epoch 50 	 0.653148 	 0.646140 	 0.643382
[Model stopped early]
Train loss       : 0.656135
Best valid loss  : 0.635570
Best test loss   : 0.634926
Pruning          : 0.06
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 65,553
--------------------------------
Total memory      : 1.12 MB
Total Flops       : 43.05 MFlops
Total Mem (Read)  : 1.59 MB
Total Mem (Write) : 859.29 KB
[Supermasks testing]
[Untrained loss : 0.9116]
[Starting training]
Epoch 0 	 0.906939 	 0.909926 	 0.911581
Epoch 10 	 0.853516 	 0.864430 	 0.845956
Epoch 20 	 0.799173 	 0.758272 	 0.749816
Epoch 30 	 0.672794 	 0.637408 	 0.626287
Epoch 40 	 0.674288 	 0.633732 	 0.620221
slurmstepd: error: *** JOB 41289111 ON cdr2594 CANCELLED AT 2020-04-30T04:57:22 DUE TO TIME LIMIT ***
