Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/esling.41289131.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already up-to-date: pip in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (19.1.1)
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting scipy (from -r requirements.txt (line 1))
Collecting torch_gpu (from -r requirements.txt (line 2))
Collecting torchvision (from -r requirements.txt (line 3))
Collecting tqdm (from -r requirements.txt (line 4))
Collecting numpy (from -r requirements.txt (line 5))
Collecting matplotlib (from -r requirements.txt (line 6))
Collecting tensorflow_gpu (from -r requirements.txt (line 7))
Collecting pandas (from -r requirements.txt (line 8))
Collecting mpmath (from -r requirements.txt (line 9))
Collecting networkx (from -r requirements.txt (line 10))
Collecting natsort (from -r requirements.txt (line 11))
Collecting joblib (from -r requirements.txt (line 12))
Collecting scikit_learn (from -r requirements.txt (line 13))
Collecting cffi (from -r requirements.txt (line 14))
Collecting pycparser (from -r requirements.txt (line 15))
Collecting audioread (from -r requirements.txt (line 16))
Collecting decorator (from -r requirements.txt (line 17))
Collecting six (from -r requirements.txt (line 18))
Collecting llvmlite (from -r requirements.txt (line 19))
Collecting numba (from -r requirements.txt (line 20))
Collecting imageio (from -r requirements.txt (line 21))
Collecting torch (from torchvision->-r requirements.txt (line 3))
Collecting pillow-simd>=4.1.1 (from torchvision->-r requirements.txt (line 3))
Collecting python-dateutil>=2.1 (from matplotlib->-r requirements.txt (line 6))
Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 6))
Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting kiwisolver>=1.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting wrapt>=1.11.1 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-applications>=1.0.8 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting opt-einsum>=2.3.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting absl-py>=0.7.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting gast==0.2.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-preprocessing>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Requirement already satisfied: wheel>=0.26; python_version >= "3" in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from tensorflow_gpu->-r requirements.txt (line 7)) (0.33.4)
Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting protobuf>=3.8.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting termcolor>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting astor>=0.6.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-pasta>=0.1.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting grpcio>=1.8.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting pytz>=2017.2 (from pandas->-r requirements.txt (line 8))
Requirement already satisfied: setuptools in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from numba->-r requirements.txt (line 20)) (41.0.1)
Collecting pillow (from imageio->-r requirements.txt (line 21))
Collecting future (from torch->torchvision->-r requirements.txt (line 3))
Collecting h5py (from keras-applications>=1.0.8->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests<3,>=2.21.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Installing collected packages: numpy, scipy, torch-gpu, six, future, torch, pillow-simd, torchvision, tqdm, python-dateutil, cycler, pyparsing, kiwisolver, matplotlib, wrapt, h5py, keras-applications, opt-einsum, protobuf, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, oauthlib, urllib3, chardet, idna, certifi, requests, requests-oauthlib, google-auth-oauthlib, markdown, werkzeug, grpcio, absl-py, tensorboard, gast, keras-preprocessing, tensorflow-estimator, termcolor, astor, google-pasta, tensorflow-gpu, pytz, pandas, mpmath, decorator, networkx, natsort, joblib, scikit-learn, pycparser, cffi, audioread, llvmlite, numba, pillow, imageio
Successfully installed absl-py-0.7.1 astor-0.8.1 audioread-2.1.6 cachetools-3.1.1 certifi-2020.4.5.1 cffi-1.13.2 chardet-3.0.4 cycler-0.10.0 decorator-4.4.2 future-0.17.1 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 idna-2.9 imageio-2.8.0 joblib-0.14.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 kiwisolver-1.1.0 llvmlite-0.31.0 markdown-3.2 matplotlib-3.2.1 mpmath-1.1.0 natsort-5.3.3 networkx-2.4 numba-0.48.0 numpy-1.18.1 oauthlib-3.1.0 opt-einsum-2.3.2 pandas-1.0.3 pillow-7.0.0 pillow-simd-7.0.0.post3 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 rsa-4.0 scikit-learn-0.22.1 scipy-1.4.1 six-1.14.0 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0 termcolor-1.1.0 torch-1.5.0 torch-gpu-1.0.0 torchvision-0.5.0 tqdm-4.40.2 urllib3-1.25.8 werkzeug-1.0.1 wrapt-1.11.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/nnAudio-0.1.0-py3-none-any.whl
Installing collected packages: nnAudio
Successfully installed nnAudio-0.1.0
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/SoundFile-0.10.3.post1-py2.py3-none-any.whl
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from SoundFile==0.10.3.post1) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from cffi>=1.0->SoundFile==0.10.3.post1) (2.20)
Installing collected packages: SoundFile
Successfully installed SoundFile-0.10.3.post1
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/resampy-0.2.2.tar.gz
Requirement already satisfied: numpy>=1.10 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.18.1)
Requirement already satisfied: scipy>=0.13 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.4.1)
Requirement already satisfied: numba>=0.32 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (0.48.0)
Requirement already satisfied: six>=1.3 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.14.0)
Requirement already satisfied: setuptools in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (41.0.1)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (0.31.0)
Building wheels for collected packages: resampy
  Building wheel for resampy (setup.py): started
  Building wheel for resampy (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/7f/a4/f3/4443d9c0e651405d78bca2bc790f21cb3914c168761d6ce287
Successfully built resampy
Installing collected packages: resampy
Successfully installed resampy-0.2.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/librosa-0.7.2.tar.gz
Requirement already satisfied: audioread>=2.0.0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (2.1.6)
Requirement already satisfied: numpy>=1.15.0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.18.1)
Requirement already satisfied: scipy>=1.0.0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.4.1)
Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.22.1)
Requirement already satisfied: joblib>=0.12 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.14.1)
Requirement already satisfied: decorator>=3.0.0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (4.4.2)
Requirement already satisfied: six>=1.3 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.14.0)
Requirement already satisfied: resampy>=0.2.2 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.2.2)
Requirement already satisfied: numba>=0.43.0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.48.0)
Requirement already satisfied: soundfile>=0.9.0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.10.3.post1)
Requirement already satisfied: setuptools in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (41.0.1)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)
Building wheels for collected packages: librosa
  Building wheel for librosa (setup.py): started
  Building wheel for librosa (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/5d/2c/70/9fd1f14d034354cd1109b858bb14d27d56a04a887581ff018b
Successfully built librosa
Installing collected packages: librosa
Successfully installed librosa-0.7.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/lmdb-0.98.tar.gz
Building wheels for collected packages: lmdb
  Building wheel for lmdb (setup.py): started
  Building wheel for lmdb (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/46/8c/ac/27ff74457451e040aa411ff52d641111b0a2481c9f8d31ca95
Successfully built lmdb
Installing collected packages: lmdb
Successfully installed lmdb-0.98
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/mir_eval-0.6.tar.gz
Requirement already satisfied: numpy>=1.7.0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (1.18.1)
Requirement already satisfied: scipy>=1.0.0 in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (1.4.1)
Requirement already satisfied: future in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (0.17.1)
Requirement already satisfied: six in /localscratch/esling.41289131.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (1.14.0)
Building wheels for collected packages: mir-eval
  Building wheel for mir-eval (setup.py): started
  Building wheel for mir-eval (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/d1/c4/fe/5455addf1ef19661b1d6285877644eefd17d5aa49a196aa983
Successfully built mir-eval
Installing collected packages: mir-eval
Successfully installed mir-eval-0.6
2020-04-29 05:00:55.409363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-04-29 05:00:55.777123: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
*******
Run info.
Optimization will be on cuda.
Model is singing_classify_cnn_xavier_masking_gradient_min_rewind_local_0.
*******
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.7537]
[Starting training]
Epoch 0 	 0.798943 	 0.677849 	 0.670864
Epoch 10 	 0.317325 	 0.354320 	 0.227757
Epoch 20 	 0.144531 	 0.238971 	 0.093658
Epoch 30 	 0.093405 	 0.187040 	 0.059283
Epoch 40 	 0.067440 	 0.173713 	 0.044853
Epoch 50 	 0.057215 	 0.161305 	 0.038511
Epoch 60 	 0.041360 	 0.149816 	 0.031710
Epoch 70 	 0.037224 	 0.149357 	 0.030515
Epoch 80 	 0.022289 	 0.153493 	 0.031526
Epoch 90 	 0.013327 	 0.154871 	 0.031158
[Model stopped early]
Train loss       : 0.017119
Best valid loss  : 0.147059
Best test loss   : 0.031158
Pruning          : 1.00
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.4714]
[Starting training]
Epoch 0 	 0.229665 	 0.185662 	 0.053768
Epoch 10 	 0.063764 	 0.160386 	 0.037316
Epoch 20 	 0.048483 	 0.152574 	 0.032721
Epoch 30 	 0.046760 	 0.159007 	 0.035754
Epoch 40 	 0.036994 	 0.154871 	 0.032261
Epoch 50 	 0.021255 	 0.152114 	 0.030882
Epoch 60 	 0.015280 	 0.156710 	 0.031250
[Model stopped early]
Train loss       : 0.014821
Best valid loss  : 0.147518
Best test loss   : 0.031250
Pruning          : 0.70
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.7537]
[Starting training]
Epoch 0 	 0.499885 	 0.490809 	 0.355055
Epoch 10 	 0.115005 	 0.183364 	 0.056618
Epoch 20 	 0.084559 	 0.178309 	 0.046507
Epoch 30 	 0.062270 	 0.174173 	 0.043290
Epoch 40 	 0.048943 	 0.164522 	 0.036213
Epoch 50 	 0.037339 	 0.160386 	 0.034467
Epoch 60 	 0.026769 	 0.161765 	 0.034007
[Model stopped early]
Train loss       : 0.021255
Best valid loss  : 0.154412
Best test loss   : 0.033088
Pruning          : 0.49
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.7537]
[Starting training]
Epoch 0 	 0.659122 	 0.761489 	 0.716636
Epoch 10 	 0.206457 	 0.244945 	 0.099357
Epoch 20 	 0.127872 	 0.191176 	 0.056158
Epoch 30 	 0.101677 	 0.186121 	 0.052665
Epoch 40 	 0.079733 	 0.171415 	 0.044485
Epoch 50 	 0.072381 	 0.166360 	 0.039982
Epoch 60 	 0.055377 	 0.175092 	 0.040993
Epoch 70 	 0.053194 	 0.161765 	 0.036673
Epoch 80 	 0.049517 	 0.162224 	 0.034559
Epoch 90 	 0.036075 	 0.160846 	 0.033824
Epoch 100 	 0.029412 	 0.156250 	 0.032353
Epoch 110 	 0.025735 	 0.154412 	 0.031066
Epoch 120 	 0.022059 	 0.157629 	 0.032537
[Model stopped early]
Train loss       : 0.022059
Best valid loss  : 0.153033
Best test loss   : 0.031618
Pruning          : 0.34
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.7537]
[Starting training]
Epoch 0 	 0.736213 	 0.862132 	 0.845312
Epoch 10 	 0.336857 	 0.442555 	 0.285754
Epoch 20 	 0.212201 	 0.278952 	 0.128676
Epoch 30 	 0.159007 	 0.221048 	 0.079136
Epoch 40 	 0.118451 	 0.199908 	 0.060938
Epoch 50 	 0.107652 	 0.180607 	 0.051471
Epoch 60 	 0.095244 	 0.187040 	 0.055055
Epoch 70 	 0.066176 	 0.176471 	 0.043842
Epoch 80 	 0.068474 	 0.167279 	 0.040717
Epoch 90 	 0.061236 	 0.171875 	 0.040901
Epoch 100 	 0.058134 	 0.168658 	 0.039062
Epoch 110 	 0.052734 	 0.164522 	 0.037592
Epoch 120 	 0.045152 	 0.170496 	 0.038879
Epoch 130 	 0.042739 	 0.163603 	 0.035937
[Model stopped early]
Train loss       : 0.043313
Best valid loss  : 0.161305
Best test loss   : 0.036121
Pruning          : 0.24
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.7537]
[Starting training]
Epoch 0 	 0.787799 	 0.945772 	 0.941912
Epoch 10 	 0.606733 	 0.943474 	 0.939338
Epoch 20 	 0.443130 	 0.733456 	 0.700552
Epoch 30 	 0.345703 	 0.657629 	 0.592923
Epoch 40 	 0.286535 	 0.455882 	 0.352757
Epoch 50 	 0.255170 	 0.374081 	 0.251746
Epoch 60 	 0.210823 	 0.274816 	 0.156618
Epoch 70 	 0.197725 	 0.242188 	 0.118474
Epoch 80 	 0.179688 	 0.220129 	 0.096415
Epoch 90 	 0.156939 	 0.206342 	 0.083364
Epoch 100 	 0.158778 	 0.198529 	 0.070312
Epoch 110 	 0.131319 	 0.190257 	 0.064062
Epoch 120 	 0.116498 	 0.183364 	 0.058640
Epoch 130 	 0.114775 	 0.183364 	 0.056801
Epoch 140 	 0.114660 	 0.182904 	 0.061029
Epoch 150 	 0.104320 	 0.181066 	 0.055699
Train loss       : 0.100184
Best valid loss  : 0.164062
Best test loss   : 0.047335
Pruning          : 0.17
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.7537]
[Starting training]
Epoch 0 	 0.813879 	 0.945772 	 0.942096
Epoch 10 	 0.742532 	 0.796415 	 0.794853
Epoch 20 	 0.703470 	 0.796875 	 0.794853
Epoch 30 	 0.702780 	 0.796415 	 0.794853
Epoch 40 	 0.702321 	 0.796875 	 0.794853
Epoch 50 	 0.698874 	 0.789062 	 0.788603
Epoch 60 	 0.693704 	 0.728860 	 0.688419
Epoch 70 	 0.695887 	 0.661305 	 0.643750
Epoch 80 	 0.693130 	 0.655790 	 0.640993
Epoch 90 	 0.692440 	 0.653493 	 0.640625
Epoch 100 	 0.698989 	 0.656250 	 0.640993
[Model stopped early]
Train loss       : 0.691062
Best valid loss  : 0.643842
Best test loss   : 0.613419
Pruning          : 0.12
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.7537]
[Starting training]
Epoch 0 	 0.815142 	 0.945312 	 0.942096
Epoch 10 	 0.758617 	 0.945312 	 0.942096
Epoch 20 	 0.759306 	 0.945772 	 0.942096
Epoch 30 	 0.756549 	 0.945312 	 0.942096
Epoch 40 	 0.756204 	 0.757812 	 0.753676
Epoch 50 	 0.755170 	 0.756893 	 0.753676
Epoch 60 	 0.757238 	 0.758272 	 0.753676
Epoch 70 	 0.755170 	 0.757353 	 0.753676
[Model stopped early]
Train loss       : 0.753102
Best valid loss  : 0.756893
Best test loss   : 0.753676
Pruning          : 0.08
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9116]
[Starting training]
Epoch 0 	 0.800322 	 0.945312 	 0.942096
Epoch 10 	 0.758732 	 0.873162 	 0.876471
Epoch 20 	 0.759306 	 0.873621 	 0.876471
Epoch 30 	 0.753562 	 0.873162 	 0.876471
[Model stopped early]
Train loss       : 0.756434
Best valid loss  : 0.873162
Best test loss   : 0.876471
Pruning          : 0.06
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9116]
[Starting training]
Epoch 0 	 0.794003 	 0.945312 	 0.942096
Epoch 10 	 0.756549 	 0.873162 	 0.876471
Epoch 20 	 0.754251 	 0.873621 	 0.876471
Epoch 30 	 0.754481 	 0.873621 	 0.876471
[Model stopped early]
Train loss       : 0.755974
Best valid loss  : 0.796415
Best test loss   : 0.794853
Pruning          : 0.04
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9116]
[Starting training]
Epoch 0 	 0.763672 	 0.796415 	 0.794853
Epoch 10 	 0.757698 	 0.797335 	 0.794853
Epoch 20 	 0.761374 	 0.757353 	 0.753676
Epoch 30 	 0.754366 	 0.796415 	 0.794853
[Model stopped early]
Train loss       : 0.755055
Best valid loss  : 0.756893
Best test loss   : 0.753676
Pruning          : 0.03
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9116]
[Starting training]
Epoch 0 	 0.759881 	 0.796875 	 0.794853
Epoch 10 	 0.754366 	 0.796415 	 0.794853
Epoch 20 	 0.754366 	 0.796875 	 0.794853
Epoch 30 	 0.753791 	 0.796875 	 0.794853
[Model stopped early]
Train loss       : 0.753102
Best valid loss  : 0.796415
Best test loss   : 0.794853
Pruning          : 0.02
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9116]
[Starting training]
Epoch 0 	 0.757008 	 0.796875 	 0.794853
Epoch 10 	 0.752528 	 0.797335 	 0.794853
Epoch 20 	 0.754596 	 0.796415 	 0.794853
Epoch 30 	 0.753332 	 0.797335 	 0.794853
[Model stopped early]
Train loss       : 0.753217
Best valid loss  : 0.796415
Best test loss   : 0.794853
Pruning          : 0.01
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9116]
[Starting training]
Epoch 0 	 0.756089 	 0.796875 	 0.794853
Epoch 10 	 0.752528 	 0.796415 	 0.794853
Epoch 20 	 0.754021 	 0.796415 	 0.794853
Epoch 30 	 0.753102 	 0.796415 	 0.794853
[Model stopped early]
Train loss       : 0.752987
Best valid loss  : 0.796415
Best test loss   : 0.794853
Pruning          : 0.01
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9116]
[Starting training]
Epoch 0 	 0.757583 	 0.796875 	 0.794853
Epoch 10 	 0.755170 	 0.797335 	 0.794853
Epoch 20 	 0.753906 	 0.757353 	 0.753676
Epoch 30 	 0.753332 	 0.757812 	 0.753676
Epoch 40 	 0.753562 	 0.757353 	 0.753676
[Model stopped early]
Train loss       : 0.752872
Best valid loss  : 0.756893
Best test loss   : 0.753676
Pruning          : 0.01
