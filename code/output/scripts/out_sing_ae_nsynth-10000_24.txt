Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/esling.40871936.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already up-to-date: pip in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (19.1.1)
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting scipy (from -r requirements.txt (line 1))
Collecting torch_gpu (from -r requirements.txt (line 2))
Collecting torchvision (from -r requirements.txt (line 3))
Collecting tqdm (from -r requirements.txt (line 4))
Collecting numpy (from -r requirements.txt (line 5))
Collecting matplotlib (from -r requirements.txt (line 6))
Collecting tensorflow_gpu (from -r requirements.txt (line 7))
Collecting pandas (from -r requirements.txt (line 8))
Collecting mpmath (from -r requirements.txt (line 9))
Collecting networkx (from -r requirements.txt (line 10))
Collecting natsort (from -r requirements.txt (line 11))
Collecting joblib (from -r requirements.txt (line 12))
Collecting scikit_learn (from -r requirements.txt (line 13))
Collecting cffi (from -r requirements.txt (line 14))
Collecting pycparser (from -r requirements.txt (line 15))
Collecting audioread (from -r requirements.txt (line 16))
Collecting decorator (from -r requirements.txt (line 17))
Collecting six (from -r requirements.txt (line 18))
Collecting llvmlite (from -r requirements.txt (line 19))
Collecting numba (from -r requirements.txt (line 20))
Collecting imageio (from -r requirements.txt (line 21))
Collecting pillow-simd>=4.1.1 (from torchvision->-r requirements.txt (line 3))
Collecting torch (from torchvision->-r requirements.txt (line 3))
Collecting kiwisolver>=1.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 6))
Collecting python-dateutil>=2.1 (from matplotlib->-r requirements.txt (line 6))
Collecting google-pasta>=0.1.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting termcolor>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting wrapt>=1.11.1 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-preprocessing>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting opt-einsum>=2.3.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting absl-py>=0.7.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting grpcio>=1.8.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Requirement already satisfied: wheel>=0.26; python_version >= "3" in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from tensorflow_gpu->-r requirements.txt (line 7)) (0.33.4)
Collecting astor>=0.6.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting protobuf>=3.8.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting gast==0.2.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-applications>=1.0.8 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting pytz>=2017.2 (from pandas->-r requirements.txt (line 8))
Requirement already satisfied: setuptools in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from numba->-r requirements.txt (line 20)) (41.0.1)
Collecting pillow (from imageio->-r requirements.txt (line 21))
Collecting future (from torch->torchvision->-r requirements.txt (line 3))
Collecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests<3,>=2.21.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting h5py (from keras-applications>=1.0.8->tensorflow_gpu->-r requirements.txt (line 7))
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Installing collected packages: numpy, scipy, torch-gpu, pillow-simd, future, torch, six, torchvision, tqdm, kiwisolver, pyparsing, cycler, python-dateutil, matplotlib, google-pasta, termcolor, tensorflow-estimator, wrapt, keras-preprocessing, opt-einsum, absl-py, grpcio, werkzeug, urllib3, certifi, idna, chardet, requests, markdown, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, protobuf, tensorboard, astor, gast, h5py, keras-applications, tensorflow-gpu, pytz, pandas, mpmath, decorator, networkx, natsort, joblib, scikit-learn, pycparser, cffi, audioread, llvmlite, numba, pillow, imageio
Successfully installed absl-py-0.7.1 astor-0.8.1 audioread-2.1.6 cachetools-3.1.1 certifi-2020.4.5.1 cffi-1.13.2 chardet-3.0.4 cycler-0.10.0 decorator-4.4.2 future-0.17.1 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 idna-2.9 imageio-2.8.0 joblib-0.14.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 kiwisolver-1.1.0 llvmlite-0.31.0 markdown-3.2 matplotlib-3.2.1 mpmath-1.1.0 natsort-5.3.3 networkx-2.4 numba-0.48.0 numpy-1.18.1 oauthlib-3.1.0 opt-einsum-2.3.2 pandas-1.0.3 pillow-7.0.0 pillow-simd-7.0.0.post3 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 rsa-4.0 scikit-learn-0.22.1 scipy-1.4.1 six-1.14.0 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0 termcolor-1.1.0 torch-1.5.0 torch-gpu-1.0.0 torchvision-0.5.0 tqdm-4.40.2 urllib3-1.25.8 werkzeug-1.0.1 wrapt-1.11.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/nnAudio-0.1.0-py3-none-any.whl
Installing collected packages: nnAudio
Successfully installed nnAudio-0.1.0
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/SoundFile-0.10.3.post1-py2.py3-none-any.whl
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from SoundFile==0.10.3.post1) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from cffi>=1.0->SoundFile==0.10.3.post1) (2.20)
Installing collected packages: SoundFile
Successfully installed SoundFile-0.10.3.post1
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/resampy-0.2.2.tar.gz
Requirement already satisfied: numpy>=1.10 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.18.1)
Requirement already satisfied: scipy>=0.13 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.4.1)
Requirement already satisfied: numba>=0.32 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (0.48.0)
Requirement already satisfied: six>=1.3 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.14.0)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (0.31.0)
Requirement already satisfied: setuptools in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (41.0.1)
Building wheels for collected packages: resampy
  Building wheel for resampy (setup.py): started
  Building wheel for resampy (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/7f/a4/f3/4443d9c0e651405d78bca2bc790f21cb3914c168761d6ce287
Successfully built resampy
Installing collected packages: resampy
Successfully installed resampy-0.2.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/librosa-0.7.2.tar.gz
Requirement already satisfied: audioread>=2.0.0 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (2.1.6)
Requirement already satisfied: numpy>=1.15.0 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.18.1)
Requirement already satisfied: scipy>=1.0.0 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.4.1)
Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.22.1)
Requirement already satisfied: joblib>=0.12 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.14.1)
Requirement already satisfied: decorator>=3.0.0 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (4.4.2)
Requirement already satisfied: six>=1.3 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.14.0)
Requirement already satisfied: resampy>=0.2.2 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.2.2)
Requirement already satisfied: numba>=0.43.0 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.48.0)
Requirement already satisfied: soundfile>=0.9.0 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.10.3.post1)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)
Requirement already satisfied: setuptools in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (41.0.1)
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.40871936.0/env/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)
Building wheels for collected packages: librosa
  Building wheel for librosa (setup.py): started
  Building wheel for librosa (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/5d/2c/70/9fd1f14d034354cd1109b858bb14d27d56a04a887581ff018b
Successfully built librosa
Installing collected packages: librosa
Successfully installed librosa-0.7.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/lmdb-0.98.tar.gz
Building wheels for collected packages: lmdb
  Building wheel for lmdb (setup.py): started
  Building wheel for lmdb (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/46/8c/ac/27ff74457451e040aa411ff52d641111b0a2481c9f8d31ca95
Successfully built lmdb
Installing collected packages: lmdb
Successfully installed lmdb-0.98
2020-04-22 07:35:00.355103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-04-22 07:35:00.685626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
*******
Run info.
Optimization will be on cuda.
Model is nsynth-10000_sing_ae_cnn_xavier_masking_magnitude_reinit_local_0.
*******
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5981]
[Starting training]
Epoch 0 	 0.458386 	 0.421280 	 0.425995
Epoch 10 	 0.207138 	 0.215378 	 0.218724
Epoch 20 	 0.166766 	 0.179057 	 0.183293
Epoch 30 	 0.155467 	 0.165144 	 0.169757
Epoch 40 	 0.143424 	 0.158761 	 0.160408
Epoch 50 	 0.139706 	 0.152959 	 0.156998
Epoch 60 	 0.136852 	 0.157821 	 0.160394
Epoch 70 	 0.129169 	 0.147413 	 0.148830
Epoch 80 	 0.132496 	 0.147678 	 0.148326
Epoch 90 	 0.124556 	 0.146942 	 0.147250
Epoch 100 	 0.123567 	 0.142592 	 0.143130
Epoch 110 	 0.110094 	 0.132638 	 0.134269
Epoch 120 	 0.103854 	 0.128745 	 0.130003
Epoch 130 	 0.101632 	 0.128530 	 0.129144
Epoch 140 	 0.100327 	 0.129597 	 0.129183
Epoch 150 	 0.096063 	 0.125243 	 0.126279
Train loss       : 0.095587
Best valid loss  : 0.123412
Best test loss   : 0.126261
Pruning          : 1.00
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5785]
[Starting training]
Epoch 0 	 0.463246 	 0.432379 	 0.434135
Epoch 10 	 0.234524 	 0.236417 	 0.240400
Epoch 20 	 0.185633 	 0.192204 	 0.197060
Epoch 30 	 0.167252 	 0.181927 	 0.186193
Epoch 40 	 0.158750 	 0.173961 	 0.175357
Epoch 50 	 0.151175 	 0.164576 	 0.169280
Epoch 60 	 0.144969 	 0.160435 	 0.162112
Epoch 70 	 0.142327 	 0.159802 	 0.161568
Epoch 80 	 0.127246 	 0.150058 	 0.150886
Epoch 90 	 0.126136 	 0.148159 	 0.150987
Epoch 100 	 0.117399 	 0.141926 	 0.144782
Epoch 110 	 0.116545 	 0.141511 	 0.144855
Epoch 120 	 0.115538 	 0.140645 	 0.144539
Epoch 130 	 0.110891 	 0.139662 	 0.142049
Epoch 140 	 0.110465 	 0.139375 	 0.142371
Epoch 150 	 0.108315 	 0.137725 	 0.140982
Train loss       : 0.108095
Best valid loss  : 0.134447
Best test loss   : 0.140929
Pruning          : 0.70
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5334]
[Starting training]
Epoch 0 	 0.456502 	 0.427128 	 0.429179
Epoch 10 	 0.240734 	 0.242952 	 0.245421
Epoch 20 	 0.187738 	 0.192524 	 0.198712
Epoch 30 	 0.169966 	 0.182920 	 0.186031
Epoch 40 	 0.158466 	 0.167510 	 0.171895
Epoch 50 	 0.152733 	 0.165865 	 0.167049
Epoch 60 	 0.146953 	 0.160580 	 0.162364
Epoch 70 	 0.141880 	 0.158374 	 0.160719
Epoch 80 	 0.139736 	 0.151679 	 0.157679
Epoch 90 	 0.135983 	 0.154625 	 0.155460
Epoch 100 	 0.134016 	 0.152452 	 0.157045
Epoch 110 	 0.121046 	 0.141181 	 0.143821
Epoch 120 	 0.120046 	 0.143513 	 0.144759
Epoch 130 	 0.119012 	 0.142200 	 0.143864
Epoch 140 	 0.112438 	 0.138107 	 0.138991
Epoch 150 	 0.111775 	 0.137180 	 0.138455
Train loss       : 0.107876
Best valid loss  : 0.132768
Best test loss   : 0.136262
Pruning          : 0.49
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5836]
[Starting training]
Epoch 0 	 0.480111 	 0.448713 	 0.451537
Epoch 10 	 0.262854 	 0.266220 	 0.264999
Epoch 20 	 0.201309 	 0.208629 	 0.209406
Epoch 30 	 0.178250 	 0.186412 	 0.188754
Epoch 40 	 0.164056 	 0.179890 	 0.180699
Epoch 50 	 0.159392 	 0.169901 	 0.172071
Epoch 60 	 0.152160 	 0.164019 	 0.167178
Epoch 70 	 0.147164 	 0.158295 	 0.162243
Epoch 80 	 0.144263 	 0.155830 	 0.160100
Epoch 90 	 0.139717 	 0.154227 	 0.158044
Epoch 100 	 0.137304 	 0.151730 	 0.154218
Epoch 110 	 0.126096 	 0.142367 	 0.145762
Epoch 120 	 0.120293 	 0.136613 	 0.141063
Epoch 130 	 0.117922 	 0.139089 	 0.140435
Epoch 140 	 0.114617 	 0.136568 	 0.138470
Epoch 150 	 0.114166 	 0.137147 	 0.138025
Train loss       : 0.113606
Best valid loss  : 0.132641
Best test loss   : 0.137721
Pruning          : 0.34
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5713]
[Starting training]
Epoch 0 	 0.503241 	 0.502993 	 0.511461
Epoch 10 	 0.501149 	 0.507921 	 0.509190
Epoch 20 	 0.500664 	 0.504785 	 0.509079
Epoch 30 	 0.500592 	 0.506329 	 0.508985
Epoch 40 	 0.499943 	 0.500830 	 0.508943
Epoch 50 	 0.500045 	 0.501678 	 0.508985
Epoch 60 	 0.500402 	 0.505165 	 0.508960
[Model stopped early]
Train loss       : 0.500089
Best valid loss  : 0.500229
Best test loss   : 0.508996
Pruning          : 0.24
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5911]
[Starting training]
Epoch 0 	 0.504456 	 0.500594 	 0.509758
Epoch 10 	 0.500783 	 0.505932 	 0.509407
Epoch 20 	 0.500375 	 0.503895 	 0.509086
Epoch 30 	 0.500522 	 0.501680 	 0.509019
[Model stopped early]
Train loss       : 0.500486
Best valid loss  : 0.500594
Best test loss   : 0.509758
Pruning          : 0.17
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5705]
[Starting training]
Epoch 0 	 0.503557 	 0.505248 	 0.509303
Epoch 10 	 0.500422 	 0.506195 	 0.510011
Epoch 20 	 0.500414 	 0.504853 	 0.509110
Epoch 30 	 0.500719 	 0.508509 	 0.509102
Epoch 40 	 0.500567 	 0.502949 	 0.508994
Epoch 50 	 0.500378 	 0.504695 	 0.508955
Epoch 60 	 0.500250 	 0.505365 	 0.508955
Epoch 70 	 0.500701 	 0.503095 	 0.508927
Epoch 80 	 0.500395 	 0.504189 	 0.508931
[Model stopped early]
Train loss       : 0.500462
Best valid loss  : 0.497312
Best test loss   : 0.508947
Pruning          : 0.12
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5357]
[Starting training]
Epoch 0 	 0.502471 	 0.503488 	 0.509607
Epoch 10 	 0.500994 	 0.503154 	 0.509658
Epoch 20 	 0.500779 	 0.502253 	 0.509169
Epoch 30 	 0.500205 	 0.506505 	 0.509369
Epoch 40 	 0.500514 	 0.499709 	 0.509091
Epoch 50 	 0.500221 	 0.505297 	 0.509236
Epoch 60 	 0.500163 	 0.502846 	 0.509079
Epoch 70 	 0.499807 	 0.505659 	 0.508936
Epoch 80 	 0.500756 	 0.501669 	 0.508994
Epoch 90 	 0.500431 	 0.503635 	 0.509001
Epoch 100 	 0.500716 	 0.504003 	 0.508936
[Model stopped early]
Train loss       : 0.500128
Best valid loss  : 0.498065
Best test loss   : 0.508997
Pruning          : 0.08
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.6001]
[Starting training]
Epoch 0 	 0.507217 	 0.506806 	 0.509508
Epoch 10 	 0.501166 	 0.504887 	 0.509130
Epoch 20 	 0.499960 	 0.504546 	 0.509190
Epoch 30 	 0.500234 	 0.504971 	 0.509077
Epoch 40 	 0.499783 	 0.503580 	 0.508976
Epoch 50 	 0.500564 	 0.503144 	 0.508976
Epoch 60 	 0.500590 	 0.507434 	 0.508954
Epoch 70 	 0.499629 	 0.504221 	 0.508933
[Model stopped early]
Train loss       : 0.500266
Best valid loss  : 0.494813
Best test loss   : 0.509006
Pruning          : 0.06
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5897]
[Starting training]
Epoch 0 	 0.507630 	 0.500553 	 0.509603
Epoch 10 	 0.500338 	 0.504492 	 0.509337
Epoch 20 	 0.499997 	 0.501823 	 0.508965
Epoch 30 	 0.500549 	 0.502758 	 0.509030
[Model stopped early]
Train loss       : 0.500660
Best valid loss  : 0.499814
Best test loss   : 0.509187
Pruning          : 0.04
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5573]
[Starting training]
Epoch 0 	 0.505305 	 0.501730 	 0.509199
Epoch 10 	 0.500991 	 0.501898 	 0.509565
Epoch 20 	 0.500674 	 0.506357 	 0.509364
Epoch 30 	 0.500662 	 0.504407 	 0.509048
Epoch 40 	 0.500512 	 0.504295 	 0.508946
Epoch 50 	 0.499970 	 0.504052 	 0.508933
[Model stopped early]
Train loss       : 0.500797
Best valid loss  : 0.494357
Best test loss   : 0.509035
Pruning          : 0.03
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5586]
[Starting training]
Epoch 0 	 0.507210 	 0.505013 	 0.509195
Epoch 10 	 0.500145 	 0.502455 	 0.509204
Epoch 20 	 0.500334 	 0.505402 	 0.509080
Epoch 30 	 0.500327 	 0.501665 	 0.509057
[Model stopped early]
Train loss       : 0.500795
Best valid loss  : 0.501061
Best test loss   : 0.509297
Pruning          : 0.02
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5897]
[Starting training]
Epoch 0 	 0.511109 	 0.502479 	 0.509166
Epoch 10 	 0.500830 	 0.506339 	 0.509639
Epoch 20 	 0.499500 	 0.506969 	 0.509098
Epoch 30 	 0.500144 	 0.502019 	 0.508973
[Model stopped early]
Train loss       : 0.500275
Best valid loss  : 0.499716
Best test loss   : 0.509151
Pruning          : 0.01
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5650]
[Starting training]
Epoch 0 	 0.510106 	 0.503992 	 0.509087
Epoch 10 	 0.500385 	 0.501074 	 0.509223
Epoch 20 	 0.500560 	 0.503168 	 0.509047
Epoch 30 	 0.500266 	 0.501491 	 0.508952
[Model stopped early]
Train loss       : 0.500674
Best valid loss  : 0.500029
Best test loss   : 0.509202
Pruning          : 0.01
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5638]
[Starting training]
Epoch 0 	 0.511072 	 0.502950 	 0.509229
Epoch 10 	 0.499868 	 0.507320 	 0.509248
Epoch 20 	 0.500771 	 0.506541 	 0.509156
Epoch 30 	 0.500377 	 0.501988 	 0.509401
Epoch 40 	 0.500347 	 0.495179 	 0.509131
Epoch 50 	 0.500453 	 0.504162 	 0.509008
Epoch 60 	 0.500870 	 0.506069 	 0.509004
Epoch 70 	 0.500264 	 0.507174 	 0.508931
[Model stopped early]
Train loss       : 0.500337
Best valid loss  : 0.495179
Best test loss   : 0.509131
Pruning          : 0.01
