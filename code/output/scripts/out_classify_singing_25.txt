Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/esling.41289117.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already up-to-date: pip in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (19.1.1)
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting scipy (from -r requirements.txt (line 1))
Collecting torch_gpu (from -r requirements.txt (line 2))
Collecting torchvision (from -r requirements.txt (line 3))
Collecting tqdm (from -r requirements.txt (line 4))
Collecting numpy (from -r requirements.txt (line 5))
Collecting matplotlib (from -r requirements.txt (line 6))
Collecting tensorflow_gpu (from -r requirements.txt (line 7))
Collecting pandas (from -r requirements.txt (line 8))
Collecting mpmath (from -r requirements.txt (line 9))
Collecting networkx (from -r requirements.txt (line 10))
Collecting natsort (from -r requirements.txt (line 11))
Collecting joblib (from -r requirements.txt (line 12))
Collecting scikit_learn (from -r requirements.txt (line 13))
Collecting cffi (from -r requirements.txt (line 14))
Collecting pycparser (from -r requirements.txt (line 15))
Collecting audioread (from -r requirements.txt (line 16))
Collecting decorator (from -r requirements.txt (line 17))
Collecting six (from -r requirements.txt (line 18))
Collecting llvmlite (from -r requirements.txt (line 19))
Collecting numba (from -r requirements.txt (line 20))
Collecting imageio (from -r requirements.txt (line 21))
Collecting pillow-simd>=4.1.1 (from torchvision->-r requirements.txt (line 3))
Collecting torch (from torchvision->-r requirements.txt (line 3))
Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 6))
Collecting python-dateutil>=2.1 (from matplotlib->-r requirements.txt (line 6))
Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting kiwisolver>=1.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting gast==0.2.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting absl-py>=0.7.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting termcolor>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting grpcio>=1.8.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-pasta>=0.1.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting protobuf>=3.8.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-applications>=1.0.8 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting opt-einsum>=2.3.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-preprocessing>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Requirement already satisfied: wheel>=0.26; python_version >= "3" in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from tensorflow_gpu->-r requirements.txt (line 7)) (0.33.4)
Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting wrapt>=1.11.1 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting astor>=0.6.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting pytz>=2017.2 (from pandas->-r requirements.txt (line 8))
Requirement already satisfied: setuptools in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from numba->-r requirements.txt (line 20)) (41.0.1)
Collecting pillow (from imageio->-r requirements.txt (line 21))
Collecting future (from torch->torchvision->-r requirements.txt (line 3))
Collecting h5py (from keras-applications>=1.0.8->tensorflow_gpu->-r requirements.txt (line 7))
Collecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests<3,>=2.21.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Installing collected packages: numpy, scipy, torch-gpu, pillow-simd, six, future, torch, torchvision, tqdm, cycler, python-dateutil, pyparsing, kiwisolver, matplotlib, gast, absl-py, termcolor, grpcio, google-pasta, protobuf, h5py, keras-applications, opt-einsum, keras-preprocessing, tensorflow-estimator, wrapt, astor, werkzeug, urllib3, certifi, chardet, idna, requests, oauthlib, requests-oauthlib, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, google-auth-oauthlib, markdown, tensorboard, tensorflow-gpu, pytz, pandas, mpmath, decorator, networkx, natsort, joblib, scikit-learn, pycparser, cffi, audioread, llvmlite, numba, pillow, imageio
Successfully installed absl-py-0.7.1 astor-0.8.1 audioread-2.1.6 cachetools-3.1.1 certifi-2020.4.5.1 cffi-1.13.2 chardet-3.0.4 cycler-0.10.0 decorator-4.4.2 future-0.17.1 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 idna-2.9 imageio-2.8.0 joblib-0.14.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 kiwisolver-1.1.0 llvmlite-0.31.0 markdown-3.2 matplotlib-3.2.1 mpmath-1.1.0 natsort-5.3.3 networkx-2.4 numba-0.48.0 numpy-1.18.1 oauthlib-3.1.0 opt-einsum-2.3.2 pandas-1.0.3 pillow-7.0.0 pillow-simd-7.0.0.post3 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 rsa-4.0 scikit-learn-0.22.1 scipy-1.4.1 six-1.14.0 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0 termcolor-1.1.0 torch-1.5.0 torch-gpu-1.0.0 torchvision-0.5.0 tqdm-4.40.2 urllib3-1.25.8 werkzeug-1.0.1 wrapt-1.11.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/nnAudio-0.1.0-py3-none-any.whl
Installing collected packages: nnAudio
Successfully installed nnAudio-0.1.0
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/SoundFile-0.10.3.post1-py2.py3-none-any.whl
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from SoundFile==0.10.3.post1) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from cffi>=1.0->SoundFile==0.10.3.post1) (2.20)
Installing collected packages: SoundFile
Successfully installed SoundFile-0.10.3.post1
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/resampy-0.2.2.tar.gz
Requirement already satisfied: numpy>=1.10 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.18.1)
Requirement already satisfied: scipy>=0.13 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.4.1)
Requirement already satisfied: numba>=0.32 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (0.48.0)
Requirement already satisfied: six>=1.3 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.14.0)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (0.31.0)
Requirement already satisfied: setuptools in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (41.0.1)
Building wheels for collected packages: resampy
  Building wheel for resampy (setup.py): started
  Building wheel for resampy (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/7f/a4/f3/4443d9c0e651405d78bca2bc790f21cb3914c168761d6ce287
Successfully built resampy
Installing collected packages: resampy
Successfully installed resampy-0.2.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/librosa-0.7.2.tar.gz
Requirement already satisfied: audioread>=2.0.0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (2.1.6)
Requirement already satisfied: numpy>=1.15.0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.18.1)
Requirement already satisfied: scipy>=1.0.0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.4.1)
Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.22.1)
Requirement already satisfied: joblib>=0.12 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.14.1)
Requirement already satisfied: decorator>=3.0.0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (4.4.2)
Requirement already satisfied: six>=1.3 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.14.0)
Requirement already satisfied: resampy>=0.2.2 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.2.2)
Requirement already satisfied: numba>=0.43.0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.48.0)
Requirement already satisfied: soundfile>=0.9.0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.10.3.post1)
Requirement already satisfied: setuptools in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (41.0.1)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)
Building wheels for collected packages: librosa
  Building wheel for librosa (setup.py): started
  Building wheel for librosa (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/5d/2c/70/9fd1f14d034354cd1109b858bb14d27d56a04a887581ff018b
Successfully built librosa
Installing collected packages: librosa
Successfully installed librosa-0.7.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/lmdb-0.98.tar.gz
Building wheels for collected packages: lmdb
  Building wheel for lmdb (setup.py): started
  Building wheel for lmdb (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/46/8c/ac/27ff74457451e040aa411ff52d641111b0a2481c9f8d31ca95
Successfully built lmdb
Installing collected packages: lmdb
Successfully installed lmdb-0.98
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/mir_eval-0.6.tar.gz
Requirement already satisfied: numpy>=1.7.0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (1.18.1)
Requirement already satisfied: scipy>=1.0.0 in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (1.4.1)
Requirement already satisfied: future in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (0.17.1)
Requirement already satisfied: six in /localscratch/esling.41289117.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (1.14.0)
Building wheels for collected packages: mir-eval
  Building wheel for mir-eval (setup.py): started
  Building wheel for mir-eval (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/d1/c4/fe/5455addf1ef19661b1d6285877644eefd17d5aa49a196aa983
Successfully built mir-eval
Installing collected packages: mir-eval
Successfully installed mir-eval-0.6
2020-04-29 05:00:30.615510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-04-29 05:00:30.627796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
*******
Run info.
Optimization will be on cuda.
Model is singing_classify_cnn_xavier_masking_gradient_min_reinit_local_0.
*******
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9871]
[Starting training]
Epoch 0 	 0.818130 	 0.707721 	 0.693290
Epoch 10 	 0.295841 	 0.365349 	 0.224632
Epoch 20 	 0.137753 	 0.226562 	 0.097794
Epoch 30 	 0.092256 	 0.183364 	 0.059559
Epoch 40 	 0.062730 	 0.173713 	 0.044301
Epoch 50 	 0.034582 	 0.168199 	 0.037868
Epoch 60 	 0.025161 	 0.162684 	 0.036029
Epoch 70 	 0.020910 	 0.162224 	 0.034743
Epoch 80 	 0.017923 	 0.158548 	 0.032904
[Model stopped early]
Train loss       : 0.016774
Best valid loss  : 0.157629
Best test loss   : 0.036213
Pruning          : 1.00
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9550]
[Starting training]
Epoch 0 	 0.802160 	 0.770680 	 0.769301
Epoch 10 	 0.384995 	 0.463235 	 0.318750
Epoch 20 	 0.197266 	 0.308364 	 0.143934
Epoch 30 	 0.117417 	 0.233915 	 0.086213
Epoch 40 	 0.087546 	 0.209099 	 0.066912
Epoch 50 	 0.063994 	 0.181985 	 0.046691
Epoch 60 	 0.050781 	 0.178309 	 0.043934
Epoch 70 	 0.033318 	 0.173254 	 0.038051
Epoch 80 	 0.025391 	 0.169118 	 0.036765
Epoch 90 	 0.024816 	 0.164522 	 0.034375
Epoch 100 	 0.022978 	 0.167279 	 0.035294
Epoch 110 	 0.014706 	 0.168199 	 0.035478
Epoch 120 	 0.014017 	 0.167279 	 0.034559
[Model stopped early]
Train loss       : 0.014017
Best valid loss  : 0.162684
Best test loss   : 0.034926
Pruning          : 0.70
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9421]
[Starting training]
Epoch 0 	 0.787799 	 0.697151 	 0.685754
Epoch 10 	 0.382353 	 0.466912 	 0.319485
Epoch 20 	 0.192785 	 0.290441 	 0.146324
Epoch 30 	 0.129825 	 0.220588 	 0.078860
Epoch 40 	 0.093865 	 0.204504 	 0.068842
Epoch 50 	 0.071002 	 0.181066 	 0.047794
Epoch 60 	 0.062845 	 0.180607 	 0.042831
Epoch 70 	 0.047220 	 0.172335 	 0.038971
Epoch 80 	 0.032054 	 0.173254 	 0.038051
Epoch 90 	 0.030676 	 0.168199 	 0.035478
Epoch 100 	 0.021944 	 0.168199 	 0.034559
Epoch 110 	 0.018612 	 0.167279 	 0.034375
Epoch 120 	 0.016889 	 0.169577 	 0.034743
[Model stopped early]
Train loss       : 0.016544
Best valid loss  : 0.164062
Best test loss   : 0.033640
Pruning          : 0.49
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9871]
[Starting training]
Epoch 0 	 0.824793 	 0.763327 	 0.759651
Epoch 10 	 0.390740 	 0.446232 	 0.303860
Epoch 20 	 0.217601 	 0.300092 	 0.157904
Epoch 30 	 0.136949 	 0.238051 	 0.093107
Epoch 40 	 0.106388 	 0.210478 	 0.067096
Epoch 50 	 0.078010 	 0.184743 	 0.051287
Epoch 60 	 0.069049 	 0.181985 	 0.046875
Epoch 70 	 0.061581 	 0.176471 	 0.041176
Epoch 80 	 0.049173 	 0.173713 	 0.039154
Epoch 90 	 0.036420 	 0.161765 	 0.035662
Epoch 100 	 0.029412 	 0.166360 	 0.035662
Epoch 110 	 0.027459 	 0.164062 	 0.035294
Epoch 120 	 0.021599 	 0.163603 	 0.034007
Epoch 130 	 0.020910 	 0.160846 	 0.033824
Epoch 140 	 0.016659 	 0.158548 	 0.032353
Epoch 150 	 0.014706 	 0.158088 	 0.032537
Train loss       : 0.015740
Best valid loss  : 0.153493
Best test loss   : 0.031618
Pruning          : 0.34
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.7949]
[Starting training]
Epoch 0 	 0.811811 	 0.754596 	 0.740717
Epoch 10 	 0.457376 	 0.501838 	 0.354596
Epoch 20 	 0.264246 	 0.340533 	 0.188419
Epoch 30 	 0.171875 	 0.282169 	 0.129228
Epoch 40 	 0.134881 	 0.218750 	 0.082261
Epoch 50 	 0.109490 	 0.200827 	 0.060938
Epoch 60 	 0.092486 	 0.189798 	 0.053860
Epoch 70 	 0.071461 	 0.173713 	 0.043934
Epoch 80 	 0.056296 	 0.177390 	 0.041912
Epoch 90 	 0.049058 	 0.166360 	 0.038603
Epoch 100 	 0.042279 	 0.166360 	 0.037500
Epoch 110 	 0.036075 	 0.164522 	 0.037316
Epoch 120 	 0.031365 	 0.164062 	 0.035662
Epoch 130 	 0.036650 	 0.159926 	 0.033640
Epoch 140 	 0.028148 	 0.163143 	 0.034926
Epoch 150 	 0.026425 	 0.159926 	 0.033640
Train loss       : 0.026425
Best valid loss  : 0.159467
Best test loss   : 0.033640
Pruning          : 0.24
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9669]
[Starting training]
Epoch 0 	 0.831342 	 0.792739 	 0.779320
Epoch 10 	 0.499655 	 0.705882 	 0.641085
Epoch 20 	 0.302390 	 0.521599 	 0.406250
Epoch 30 	 0.229320 	 0.413603 	 0.284559
Epoch 40 	 0.175092 	 0.327665 	 0.193382
Epoch 50 	 0.150965 	 0.255515 	 0.120772
Epoch 60 	 0.126379 	 0.224724 	 0.084559
Epoch 70 	 0.107307 	 0.197610 	 0.062960
Epoch 80 	 0.098001 	 0.203125 	 0.065074
Epoch 90 	 0.076861 	 0.188879 	 0.052757
Epoch 100 	 0.069049 	 0.189798 	 0.052022
Epoch 110 	 0.068589 	 0.187960 	 0.051471
Epoch 120 	 0.055951 	 0.178768 	 0.045588
Epoch 130 	 0.055262 	 0.179228 	 0.043934
[Model stopped early]
Train loss       : 0.052045
Best valid loss  : 0.174173
Best test loss   : 0.044853
Pruning          : 0.17
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9871]
[Starting training]
Epoch 0 	 0.806526 	 0.795037 	 0.794853
Epoch 10 	 0.571232 	 0.702206 	 0.666728
Epoch 20 	 0.417739 	 0.755055 	 0.750551
Epoch 30 	 0.347426 	 0.694853 	 0.652114
Epoch 40 	 0.307100 	 0.679688 	 0.628033
Epoch 50 	 0.281595 	 0.645680 	 0.575643
Epoch 60 	 0.267693 	 0.581801 	 0.496875
Epoch 70 	 0.246783 	 0.491268 	 0.386029
Epoch 80 	 0.233341 	 0.423713 	 0.310846
Epoch 90 	 0.211857 	 0.363971 	 0.237868
Epoch 100 	 0.197840 	 0.319853 	 0.194301
Epoch 110 	 0.196806 	 0.293658 	 0.157721
Epoch 120 	 0.187385 	 0.261489 	 0.125735
Epoch 130 	 0.177619 	 0.257812 	 0.115625
Epoch 140 	 0.164982 	 0.234835 	 0.102941
Epoch 150 	 0.163948 	 0.232537 	 0.091636
Train loss       : 0.158548
Best valid loss  : 0.220129
Best test loss   : 0.089154
Pruning          : 0.12
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.7537]
[Starting training]
Epoch 0 	 0.805262 	 0.795037 	 0.794853
Epoch 10 	 0.757583 	 0.795037 	 0.794853
Epoch 20 	 0.759536 	 0.795037 	 0.794853
Epoch 30 	 0.758961 	 0.795496 	 0.794853
[Model stopped early]
Train loss       : 0.757583
Best valid loss  : 0.795037
Best test loss   : 0.794853
Pruning          : 0.08
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9669]
[Starting training]
Epoch 0 	 0.941751 	 0.757812 	 0.753676
Epoch 10 	 0.773208 	 0.757353 	 0.753676
Epoch 20 	 0.766659 	 0.758272 	 0.753676
Epoch 30 	 0.764246 	 0.757812 	 0.753676
[Model stopped early]
Train loss       : 0.764936
Best valid loss  : 0.757353
Best test loss   : 0.753676
Pruning          : 0.06
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9669]
[Starting training]
Epoch 0 	 0.868222 	 0.758272 	 0.753676
Epoch 10 	 0.760685 	 0.795037 	 0.794853
Epoch 20 	 0.762063 	 0.795496 	 0.794853
Epoch 30 	 0.756664 	 0.795037 	 0.794853
[Model stopped early]
Train loss       : 0.765625
Best valid loss  : 0.758272
Best test loss   : 0.753676
Pruning          : 0.04
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9127]
[Starting training]
Epoch 0 	 0.919118 	 0.918199 	 0.912684
Epoch 10 	 0.761834 	 0.917739 	 0.912684
Epoch 20 	 0.760570 	 0.917739 	 0.912684
Epoch 30 	 0.761834 	 0.758272 	 0.753676
Epoch 40 	 0.754825 	 0.757353 	 0.753676
Epoch 50 	 0.762983 	 0.758272 	 0.753676
[Model stopped early]
Train loss       : 0.764591
Best valid loss  : 0.757353
Best test loss   : 0.753676
Pruning          : 0.03
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9116]
[Starting training]
Epoch 0 	 0.789522 	 0.871783 	 0.876471
Epoch 10 	 0.757927 	 0.871783 	 0.876471
Epoch 20 	 0.761144 	 0.872702 	 0.876471
Epoch 30 	 0.757008 	 0.872243 	 0.876471
[Model stopped early]
Train loss       : 0.758732
Best valid loss  : 0.871783
Best test loss   : 0.876471
Pruning          : 0.02
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.8996]
[Starting training]
Epoch 0 	 0.910501 	 0.872243 	 0.876471
Epoch 10 	 0.758387 	 0.758272 	 0.753676
Epoch 20 	 0.764361 	 0.757812 	 0.753676
Epoch 30 	 0.758502 	 0.757812 	 0.753676
[Model stopped early]
Train loss       : 0.760110
Best valid loss  : 0.757353
Best test loss   : 0.753676
Pruning          : 0.01
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9669]
[Starting training]
Epoch 0 	 0.754366 	 0.968750 	 0.966912
Epoch 10 	 0.758502 	 0.872243 	 0.876471
Epoch 20 	 0.759995 	 0.872243 	 0.876471
Epoch 30 	 0.759995 	 0.871783 	 0.876471
[Model stopped early]
Train loss       : 0.756778
Best valid loss  : 0.871783
Best test loss   : 0.876471
Pruning          : 0.01
[Performing one full cumulative epoch]
0.0001
0.0001
[Current model size]
================================
Total params      : 1,360,779
--------------------------------
Total memory      : 8.57 MB
Total Flops       : 663.37 MFlops
Total Mem (Read)  : 12.12 MB
Total Mem (Write) : 6.42 MB
[Supermasks testing]
[Untrained loss : 0.9421]
[Starting training]
Epoch 0 	 0.925207 	 0.795496 	 0.794853
Epoch 10 	 0.763097 	 0.758272 	 0.753676
Epoch 20 	 0.763212 	 0.757353 	 0.753676
Epoch 30 	 0.762293 	 0.758272 	 0.753676
Epoch 40 	 0.760455 	 0.757812 	 0.753676
[Model stopped early]
Train loss       : 0.760455
Best valid loss  : 0.757353
Best test loss   : 0.753676
Pruning          : 0.01
