Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/esling.40871924.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already up-to-date: pip in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (19.1.1)
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting scipy (from -r requirements.txt (line 1))
Collecting torch_gpu (from -r requirements.txt (line 2))
Collecting torchvision (from -r requirements.txt (line 3))
Collecting tqdm (from -r requirements.txt (line 4))
Collecting numpy (from -r requirements.txt (line 5))
Collecting matplotlib (from -r requirements.txt (line 6))
Collecting tensorflow_gpu (from -r requirements.txt (line 7))
Collecting pandas (from -r requirements.txt (line 8))
Collecting mpmath (from -r requirements.txt (line 9))
Collecting networkx (from -r requirements.txt (line 10))
Collecting natsort (from -r requirements.txt (line 11))
Collecting joblib (from -r requirements.txt (line 12))
Collecting scikit_learn (from -r requirements.txt (line 13))
Collecting cffi (from -r requirements.txt (line 14))
Collecting pycparser (from -r requirements.txt (line 15))
Collecting audioread (from -r requirements.txt (line 16))
Collecting decorator (from -r requirements.txt (line 17))
Collecting six (from -r requirements.txt (line 18))
Collecting llvmlite (from -r requirements.txt (line 19))
Collecting numba (from -r requirements.txt (line 20))
Collecting imageio (from -r requirements.txt (line 21))
Collecting pillow-simd>=4.1.1 (from torchvision->-r requirements.txt (line 3))
Collecting torch (from torchvision->-r requirements.txt (line 3))
Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 6))
Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting kiwisolver>=1.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting python-dateutil>=2.1 (from matplotlib->-r requirements.txt (line 6))
Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting gast==0.2.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting absl-py>=0.7.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-applications>=1.0.8 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-preprocessing>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting astor>=0.6.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting protobuf>=3.8.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting termcolor>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting wrapt>=1.11.1 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-pasta>=0.1.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting grpcio>=1.8.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Requirement already satisfied: wheel>=0.26; python_version >= "3" in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from tensorflow_gpu->-r requirements.txt (line 7)) (0.33.4)
Collecting opt-einsum>=2.3.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting pytz>=2017.2 (from pandas->-r requirements.txt (line 8))
Requirement already satisfied: setuptools in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from numba->-r requirements.txt (line 20)) (41.0.1)
Collecting pillow (from imageio->-r requirements.txt (line 21))
Collecting future (from torch->torchvision->-r requirements.txt (line 3))
Collecting h5py (from keras-applications>=1.0.8->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests<3,>=2.21.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Installing collected packages: numpy, scipy, torch-gpu, pillow-simd, six, future, torch, torchvision, tqdm, cycler, pyparsing, kiwisolver, python-dateutil, matplotlib, tensorflow-estimator, gast, absl-py, h5py, keras-applications, keras-preprocessing, astor, protobuf, termcolor, wrapt, google-pasta, grpcio, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, oauthlib, idna, chardet, certifi, urllib3, requests, requests-oauthlib, google-auth-oauthlib, werkzeug, markdown, tensorboard, opt-einsum, tensorflow-gpu, pytz, pandas, mpmath, decorator, networkx, natsort, joblib, scikit-learn, pycparser, cffi, audioread, llvmlite, numba, pillow, imageio
Successfully installed absl-py-0.7.1 astor-0.8.1 audioread-2.1.6 cachetools-3.1.1 certifi-2020.4.5.1 cffi-1.13.2 chardet-3.0.4 cycler-0.10.0 decorator-4.4.2 future-0.17.1 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 idna-2.9 imageio-2.8.0 joblib-0.14.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 kiwisolver-1.1.0 llvmlite-0.31.0 markdown-3.2 matplotlib-3.2.1 mpmath-1.1.0 natsort-5.3.3 networkx-2.4 numba-0.48.0 numpy-1.18.1 oauthlib-3.1.0 opt-einsum-2.3.2 pandas-1.0.3 pillow-7.0.0 pillow-simd-7.0.0.post3 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 rsa-4.0 scikit-learn-0.22.1 scipy-1.4.1 six-1.14.0 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0 termcolor-1.1.0 torch-1.5.0 torch-gpu-1.0.0 torchvision-0.5.0 tqdm-4.40.2 urllib3-1.25.8 werkzeug-1.0.1 wrapt-1.11.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/nnAudio-0.1.0-py3-none-any.whl
Installing collected packages: nnAudio
Successfully installed nnAudio-0.1.0
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/SoundFile-0.10.3.post1-py2.py3-none-any.whl
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from SoundFile==0.10.3.post1) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from cffi>=1.0->SoundFile==0.10.3.post1) (2.20)
Installing collected packages: SoundFile
Successfully installed SoundFile-0.10.3.post1
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/resampy-0.2.2.tar.gz
Requirement already satisfied: numpy>=1.10 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.18.1)
Requirement already satisfied: scipy>=0.13 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.4.1)
Requirement already satisfied: numba>=0.32 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (0.48.0)
Requirement already satisfied: six>=1.3 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.14.0)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (0.31.0)
Requirement already satisfied: setuptools in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (41.0.1)
Building wheels for collected packages: resampy
  Building wheel for resampy (setup.py): started
  Building wheel for resampy (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/7f/a4/f3/4443d9c0e651405d78bca2bc790f21cb3914c168761d6ce287
Successfully built resampy
Installing collected packages: resampy
Successfully installed resampy-0.2.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/librosa-0.7.2.tar.gz
Requirement already satisfied: audioread>=2.0.0 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (2.1.6)
Requirement already satisfied: numpy>=1.15.0 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.18.1)
Requirement already satisfied: scipy>=1.0.0 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.4.1)
Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.22.1)
Requirement already satisfied: joblib>=0.12 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.14.1)
Requirement already satisfied: decorator>=3.0.0 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (4.4.2)
Requirement already satisfied: six>=1.3 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.14.0)
Requirement already satisfied: resampy>=0.2.2 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.2.2)
Requirement already satisfied: numba>=0.43.0 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.48.0)
Requirement already satisfied: soundfile>=0.9.0 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.10.3.post1)
Requirement already satisfied: setuptools in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (41.0.1)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.40871924.0/env/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)
Building wheels for collected packages: librosa
  Building wheel for librosa (setup.py): started
  Building wheel for librosa (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/5d/2c/70/9fd1f14d034354cd1109b858bb14d27d56a04a887581ff018b
Successfully built librosa
Installing collected packages: librosa
Successfully installed librosa-0.7.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/lmdb-0.98.tar.gz
Building wheels for collected packages: lmdb
  Building wheel for lmdb (setup.py): started
  Building wheel for lmdb (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/46/8c/ac/27ff74457451e040aa411ff52d641111b0a2481c9f8d31ca95
Successfully built lmdb
Installing collected packages: lmdb
Successfully installed lmdb-0.98
2020-04-22 07:28:13.130041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-04-22 07:28:13.458863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
*******
Run info.
Optimization will be on cuda.
Model is nsynth-10000_sing_ae_cnn_xavier_trimming_batchnorm_rewind_local_0.
*******
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.5987]
[Starting training]
Epoch 0 	 0.463662 	 0.411161 	 0.416559
Epoch 10 	 0.203532 	 0.200784 	 0.204246
Epoch 20 	 0.167352 	 0.176842 	 0.177222
Epoch 30 	 0.155475 	 0.160747 	 0.161769
Epoch 40 	 0.144830 	 0.159115 	 0.158707
Epoch 50 	 0.139205 	 0.149528 	 0.150061
Epoch 60 	 0.134400 	 0.146019 	 0.147858
Epoch 70 	 0.132456 	 0.145989 	 0.145196
Epoch 80 	 0.128430 	 0.146738 	 0.142664
Epoch 90 	 0.128516 	 0.141787 	 0.141448
Epoch 100 	 0.125424 	 0.144724 	 0.143066
Epoch 110 	 0.112201 	 0.134249 	 0.133082
Epoch 120 	 0.111385 	 0.134627 	 0.134738
Epoch 130 	 0.104012 	 0.129754 	 0.128715
Epoch 140 	 0.102811 	 0.130761 	 0.128550
Epoch 150 	 0.099101 	 0.129311 	 0.126465
Train loss       : 0.097851
Best valid loss  : 0.125375
Best test loss   : 0.126403
Pruning          : 1.00
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.1448]
[Starting training]
Epoch 0 	 0.133951 	 0.146084 	 0.143968
Epoch 10 	 0.128428 	 0.146265 	 0.144328
Epoch 20 	 0.126321 	 0.147860 	 0.143597
Epoch 30 	 0.124085 	 0.140145 	 0.140615
Epoch 40 	 0.125020 	 0.142669 	 0.139979
Epoch 50 	 0.110405 	 0.134639 	 0.132211
Epoch 60 	 0.102945 	 0.129022 	 0.128384
Epoch 70 	 0.102362 	 0.129787 	 0.128309
Epoch 80 	 0.098694 	 0.128738 	 0.126180
Epoch 90 	 0.098161 	 0.127388 	 0.125879
Epoch 100 	 0.095850 	 0.126296 	 0.125092
Epoch 110 	 0.094887 	 0.127714 	 0.124946
[Model stopped early]
Train loss       : 0.094761
Best valid loss  : 0.123570
Best test loss   : 0.125995
Pruning          : 0.78
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.1448]
[Starting training]
Epoch 0 	 0.133653 	 0.147014 	 0.145726
Epoch 10 	 0.127977 	 0.142577 	 0.141725
Epoch 20 	 0.114282 	 0.135751 	 0.134613
Epoch 30 	 0.113691 	 0.134488 	 0.133384
Epoch 40 	 0.111560 	 0.135035 	 0.133763
Epoch 50 	 0.109364 	 0.133611 	 0.132137
Epoch 60 	 0.109971 	 0.136405 	 0.136055
Epoch 70 	 0.102919 	 0.128389 	 0.127286
Epoch 80 	 0.100632 	 0.127824 	 0.127275
Epoch 90 	 0.096799 	 0.126937 	 0.125542
Epoch 100 	 0.096460 	 0.128256 	 0.125219
Epoch 110 	 0.095672 	 0.125646 	 0.124828
Epoch 120 	 0.093848 	 0.124536 	 0.124348
Epoch 130 	 0.093557 	 0.126987 	 0.124187
Epoch 140 	 0.093269 	 0.126179 	 0.124259
Epoch 150 	 0.092945 	 0.125536 	 0.123749
Train loss       : 0.092067
Best valid loss  : 0.121694
Best test loss   : 0.123664
Pruning          : 0.61
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.1448]
[Starting training]
Epoch 0 	 0.131654 	 0.143646 	 0.142482
Epoch 10 	 0.125981 	 0.143313 	 0.141932
Epoch 20 	 0.127130 	 0.152653 	 0.149149
Epoch 30 	 0.112504 	 0.133508 	 0.132988
Epoch 40 	 0.111206 	 0.136552 	 0.133645
Epoch 50 	 0.110574 	 0.134003 	 0.132170
Epoch 60 	 0.109171 	 0.134397 	 0.132906
Epoch 70 	 0.101395 	 0.129120 	 0.127502
Epoch 80 	 0.100892 	 0.122665 	 0.127338
Epoch 90 	 0.100086 	 0.129221 	 0.126656
Epoch 100 	 0.096441 	 0.125710 	 0.125377
Epoch 110 	 0.094664 	 0.126270 	 0.124519
[Model stopped early]
Train loss       : 0.094539
Best valid loss  : 0.122665
Best test loss   : 0.127338
Pruning          : 0.47
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.1448]
[Starting training]
Epoch 0 	 0.133224 	 0.148272 	 0.145279
Epoch 10 	 0.126898 	 0.142359 	 0.142006
Epoch 20 	 0.125713 	 0.139207 	 0.141796
Epoch 30 	 0.125142 	 0.145566 	 0.142125
Epoch 40 	 0.111424 	 0.134955 	 0.134333
Epoch 50 	 0.110075 	 0.135436 	 0.133486
Epoch 60 	 0.102461 	 0.129371 	 0.127560
Epoch 70 	 0.102062 	 0.129560 	 0.128013
Epoch 80 	 0.101260 	 0.130733 	 0.127814
Epoch 90 	 0.097167 	 0.128366 	 0.125911
Epoch 100 	 0.095465 	 0.126072 	 0.124803
Epoch 110 	 0.094429 	 0.126179 	 0.124419
Epoch 120 	 0.093844 	 0.125429 	 0.124587
Epoch 130 	 0.093800 	 0.125928 	 0.124454
Epoch 140 	 0.093545 	 0.125877 	 0.124374
Epoch 150 	 0.093340 	 0.127295 	 0.124360
[Model stopped early]
Train loss       : 0.093414
Best valid loss  : 0.123133
Best test loss   : 0.124397
Pruning          : 0.37
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.1448]
[Starting training]
Epoch 0 	 0.132794 	 0.143536 	 0.142378
Epoch 10 	 0.129375 	 0.145679 	 0.141896
Epoch 20 	 0.127128 	 0.143913 	 0.142656
Epoch 30 	 0.125938 	 0.144740 	 0.142882
Epoch 40 	 0.122714 	 0.142739 	 0.141329
Epoch 50 	 0.113842 	 0.132706 	 0.132034
Epoch 60 	 0.109370 	 0.133450 	 0.131503
Epoch 70 	 0.102453 	 0.129917 	 0.126781
Epoch 80 	 0.101758 	 0.130581 	 0.128117
Epoch 90 	 0.098094 	 0.128404 	 0.125490
Epoch 100 	 0.096217 	 0.126333 	 0.125032
Epoch 110 	 0.095019 	 0.126404 	 0.124785
Epoch 120 	 0.094646 	 0.127092 	 0.124519
[Model stopped early]
Train loss       : 0.094504
Best valid loss  : 0.122929
Best test loss   : 0.124917
Pruning          : 0.29
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.1448]
[Starting training]
Epoch 0 	 0.134062 	 0.144164 	 0.143753
Epoch 10 	 0.128165 	 0.143391 	 0.144556
Epoch 20 	 0.113917 	 0.134538 	 0.134337
Epoch 30 	 0.113418 	 0.136980 	 0.134739
Epoch 40 	 0.110940 	 0.134489 	 0.132947
Epoch 50 	 0.103056 	 0.130905 	 0.128510
Epoch 60 	 0.102203 	 0.131474 	 0.128124
Epoch 70 	 0.098294 	 0.127848 	 0.126522
Epoch 80 	 0.097907 	 0.127921 	 0.125869
Epoch 90 	 0.096045 	 0.125470 	 0.125372
Epoch 100 	 0.095571 	 0.126186 	 0.125403
Epoch 110 	 0.095419 	 0.126927 	 0.125217
Epoch 120 	 0.094257 	 0.127484 	 0.124790
Epoch 130 	 0.093631 	 0.126395 	 0.124648
[Model stopped early]
Train loss       : 0.093711
Best valid loss  : 0.122146
Best test loss   : 0.125328
Pruning          : 0.23
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.1448]
[Starting training]
Epoch 0 	 0.133455 	 0.143330 	 0.143867
Epoch 10 	 0.129188 	 0.144160 	 0.142995
Epoch 20 	 0.125052 	 0.143545 	 0.141948
Epoch 30 	 0.125224 	 0.144933 	 0.144325
Epoch 40 	 0.111514 	 0.134536 	 0.133504
Epoch 50 	 0.110135 	 0.132737 	 0.132368
Epoch 60 	 0.103002 	 0.128928 	 0.128535
Epoch 70 	 0.102187 	 0.129871 	 0.128217
Epoch 80 	 0.098537 	 0.127979 	 0.125783
Epoch 90 	 0.096424 	 0.127240 	 0.125402
Epoch 100 	 0.095509 	 0.126667 	 0.125001
Epoch 110 	 0.095297 	 0.127027 	 0.124921
Epoch 120 	 0.094717 	 0.126112 	 0.124809
Epoch 130 	 0.094262 	 0.125873 	 0.124612
[Model stopped early]
Train loss       : 0.094445
Best valid loss  : 0.122550
Best test loss   : 0.124835
Pruning          : 0.18
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.1448]
[Starting training]
Epoch 0 	 0.132963 	 0.144961 	 0.142366
Epoch 10 	 0.130704 	 0.146605 	 0.146310
Epoch 20 	 0.124936 	 0.143260 	 0.142593
Epoch 30 	 0.112069 	 0.133852 	 0.132805
Epoch 40 	 0.111862 	 0.134859 	 0.133729
Epoch 50 	 0.110802 	 0.136543 	 0.135356
Epoch 60 	 0.109444 	 0.133455 	 0.132269
Epoch 70 	 0.101785 	 0.130287 	 0.127837
Epoch 80 	 0.097964 	 0.127091 	 0.126016
Epoch 90 	 0.097315 	 0.127085 	 0.126029
Epoch 100 	 0.096994 	 0.128972 	 0.126038
Epoch 110 	 0.094944 	 0.126037 	 0.124847
Epoch 120 	 0.094069 	 0.127309 	 0.124508
[Model stopped early]
Train loss       : 0.093775
Best valid loss  : 0.122883
Best test loss   : 0.125476
Pruning          : 0.14
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.1448]
[Starting training]
Epoch 0 	 0.133039 	 0.146075 	 0.144379
Epoch 10 	 0.127945 	 0.149939 	 0.148295
Epoch 20 	 0.125745 	 0.142927 	 0.143299
Epoch 30 	 0.112471 	 0.135288 	 0.133045
Epoch 40 	 0.111737 	 0.133972 	 0.133813
Epoch 50 	 0.110090 	 0.134977 	 0.133479
Epoch 60 	 0.104400 	 0.128138 	 0.127943
Epoch 70 	 0.101466 	 0.124384 	 0.127957
Epoch 80 	 0.101012 	 0.127934 	 0.127774
Epoch 90 	 0.097148 	 0.126853 	 0.125233
Epoch 100 	 0.095175 	 0.127464 	 0.124941
Epoch 110 	 0.094910 	 0.126346 	 0.124726
Epoch 120 	 0.093875 	 0.126477 	 0.124524
Epoch 130 	 0.093425 	 0.126278 	 0.124363
Epoch 140 	 0.093023 	 0.125114 	 0.124316
Epoch 150 	 0.093161 	 0.126177 	 0.124320
[Model stopped early]
Train loss       : 0.092719
Best valid loss  : 0.122723
Best test loss   : 0.124369
Pruning          : 0.11
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.1448]
[Starting training]
Epoch 0 	 0.132913 	 0.145873 	 0.144643
Epoch 10 	 0.128105 	 0.146000 	 0.146581
Epoch 20 	 0.113564 	 0.134021 	 0.132959
Epoch 30 	 0.112805 	 0.135914 	 0.134699
Epoch 40 	 0.111580 	 0.134235 	 0.132923
Epoch 50 	 0.103030 	 0.130728 	 0.128067
Epoch 60 	 0.102332 	 0.130129 	 0.128219
Epoch 70 	 0.098307 	 0.128179 	 0.126241
Epoch 80 	 0.097762 	 0.126346 	 0.126079
Epoch 90 	 0.097280 	 0.127219 	 0.125695
Epoch 100 	 0.095186 	 0.127053 	 0.125071
Epoch 110 	 0.094294 	 0.128004 	 0.124768
Epoch 120 	 0.093743 	 0.126907 	 0.124494
Epoch 130 	 0.093674 	 0.126135 	 0.124595
Epoch 140 	 0.093298 	 0.127101 	 0.124577
Epoch 150 	 0.093361 	 0.127590 	 0.124515
[Model stopped early]
Train loss       : 0.093361
Best valid loss  : 0.122868
Best test loss   : 0.124568
Pruning          : 0.08
0.001
0.001
[Current model size]
================================
Total params      : 21,213,200
--------------------------------
Total memory      : 23.17 MB
Total Flops       : 4.68 GFlops
Total Mem (Read)  : 94.21 MB
Total Mem (Write) : 22.94 MB
[Supermasks testing]
[Untrained loss : 0.1448]
[Starting training]
Epoch 0 	 0.134150 	 0.144618 	 0.143844
Epoch 10 	 0.127801 	 0.143359 	 0.143197
Epoch 20 	 0.125689 	 0.144943 	 0.143318
Epoch 30 	 0.115593 	 0.135354 	 0.133751
Epoch 40 	 0.110842 	 0.131467 	 0.133601
Epoch 50 	 0.109860 	 0.134592 	 0.132681
Epoch 60 	 0.102826 	 0.130273 	 0.128068
slurmstepd: error: *** JOB 40871924 ON cdr2527 CANCELLED AT 2020-04-23T07:12:24 ***
