Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/esling.40977517.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already up-to-date: pip in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (19.1.1)
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting scipy (from -r requirements.txt (line 1))
Collecting torch_gpu (from -r requirements.txt (line 2))
Collecting torchvision (from -r requirements.txt (line 3))
Collecting tqdm (from -r requirements.txt (line 4))
Collecting numpy (from -r requirements.txt (line 5))
Collecting matplotlib (from -r requirements.txt (line 6))
Collecting tensorflow_gpu (from -r requirements.txt (line 7))
Collecting pandas (from -r requirements.txt (line 8))
Collecting mpmath (from -r requirements.txt (line 9))
Collecting networkx (from -r requirements.txt (line 10))
Collecting natsort (from -r requirements.txt (line 11))
Collecting joblib (from -r requirements.txt (line 12))
Collecting scikit_learn (from -r requirements.txt (line 13))
Collecting cffi (from -r requirements.txt (line 14))
Collecting pycparser (from -r requirements.txt (line 15))
Collecting audioread (from -r requirements.txt (line 16))
Collecting decorator (from -r requirements.txt (line 17))
Collecting six (from -r requirements.txt (line 18))
Collecting llvmlite (from -r requirements.txt (line 19))
Collecting numba (from -r requirements.txt (line 20))
Collecting imageio (from -r requirements.txt (line 21))
Collecting torch (from torchvision->-r requirements.txt (line 3))
Collecting pillow-simd>=4.1.1 (from torchvision->-r requirements.txt (line 3))
Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting kiwisolver>=1.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 6))
Collecting python-dateutil>=2.1 (from matplotlib->-r requirements.txt (line 6))
Collecting protobuf>=3.8.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting opt-einsum>=2.3.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Requirement already satisfied: wheel>=0.26; python_version >= "3" in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from tensorflow_gpu->-r requirements.txt (line 7)) (0.33.4)
Collecting absl-py>=0.7.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting astor>=0.6.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting gast==0.2.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-pasta>=0.1.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-preprocessing>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-applications>=1.0.8 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting termcolor>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting grpcio>=1.8.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting wrapt>=1.11.1 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting pytz>=2017.2 (from pandas->-r requirements.txt (line 8))
Requirement already satisfied: setuptools in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from numba->-r requirements.txt (line 20)) (41.0.1)
Collecting pillow (from imageio->-r requirements.txt (line 21))
Collecting future (from torch->torchvision->-r requirements.txt (line 3))
Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests<3,>=2.21.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting h5py (from keras-applications>=1.0.8->tensorflow_gpu->-r requirements.txt (line 7))
Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Installing collected packages: numpy, scipy, torch-gpu, future, torch, pillow-simd, six, torchvision, tqdm, pyparsing, kiwisolver, cycler, python-dateutil, matplotlib, protobuf, opt-einsum, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, idna, urllib3, certifi, chardet, requests, werkzeug, absl-py, grpcio, markdown, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, astor, gast, google-pasta, tensorflow-estimator, keras-preprocessing, h5py, keras-applications, termcolor, wrapt, tensorflow-gpu, pytz, pandas, mpmath, decorator, networkx, natsort, joblib, scikit-learn, pycparser, cffi, audioread, llvmlite, numba, pillow, imageio
Successfully installed absl-py-0.7.1 astor-0.8.1 audioread-2.1.6 cachetools-3.1.1 certifi-2020.4.5.1 cffi-1.13.2 chardet-3.0.4 cycler-0.10.0 decorator-4.4.2 future-0.17.1 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 idna-2.9 imageio-2.8.0 joblib-0.14.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 kiwisolver-1.1.0 llvmlite-0.31.0 markdown-3.2 matplotlib-3.2.1 mpmath-1.1.0 natsort-5.3.3 networkx-2.4 numba-0.48.0 numpy-1.18.1 oauthlib-3.1.0 opt-einsum-2.3.2 pandas-1.0.3 pillow-7.0.0 pillow-simd-7.0.0.post3 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 rsa-4.0 scikit-learn-0.22.1 scipy-1.4.1 six-1.14.0 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0 termcolor-1.1.0 torch-1.5.0 torch-gpu-1.0.0 torchvision-0.5.0 tqdm-4.40.2 urllib3-1.25.8 werkzeug-1.0.1 wrapt-1.11.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/nnAudio-0.1.0-py3-none-any.whl
Installing collected packages: nnAudio
Successfully installed nnAudio-0.1.0
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/SoundFile-0.10.3.post1-py2.py3-none-any.whl
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from SoundFile==0.10.3.post1) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from cffi>=1.0->SoundFile==0.10.3.post1) (2.20)
Installing collected packages: SoundFile
Successfully installed SoundFile-0.10.3.post1
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/resampy-0.2.2.tar.gz
Requirement already satisfied: numpy>=1.10 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.18.1)
Requirement already satisfied: scipy>=0.13 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.4.1)
Requirement already satisfied: numba>=0.32 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (0.48.0)
Requirement already satisfied: six>=1.3 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.14.0)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (0.31.0)
Requirement already satisfied: setuptools in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (41.0.1)
Building wheels for collected packages: resampy
  Building wheel for resampy (setup.py): started
  Building wheel for resampy (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/7f/a4/f3/4443d9c0e651405d78bca2bc790f21cb3914c168761d6ce287
Successfully built resampy
Installing collected packages: resampy
Successfully installed resampy-0.2.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/librosa-0.7.2.tar.gz
Requirement already satisfied: audioread>=2.0.0 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (2.1.6)
Requirement already satisfied: numpy>=1.15.0 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.18.1)
Requirement already satisfied: scipy>=1.0.0 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.4.1)
Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.22.1)
Requirement already satisfied: joblib>=0.12 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.14.1)
Requirement already satisfied: decorator>=3.0.0 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (4.4.2)
Requirement already satisfied: six>=1.3 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.14.0)
Requirement already satisfied: resampy>=0.2.2 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.2.2)
Requirement already satisfied: numba>=0.43.0 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.48.0)
Requirement already satisfied: soundfile>=0.9.0 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.10.3.post1)
Requirement already satisfied: setuptools in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (41.0.1)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.40977517.0/env/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)
Building wheels for collected packages: librosa
  Building wheel for librosa (setup.py): started
  Building wheel for librosa (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/5d/2c/70/9fd1f14d034354cd1109b858bb14d27d56a04a887581ff018b
Successfully built librosa
Installing collected packages: librosa
Successfully installed librosa-0.7.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/lmdb-0.98.tar.gz
Building wheels for collected packages: lmdb
  Building wheel for lmdb (setup.py): started
  Building wheel for lmdb (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/46/8c/ac/27ff74457451e040aa411ff52d641111b0a2481c9f8d31ca95
Successfully built lmdb
Installing collected packages: lmdb
Successfully installed lmdb-0.98
2020-04-24 12:15:51.144888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-04-24 12:15:51.494945: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
*******
Run info.
Optimization will be on cuda.
Model is nsynth-10000_ddsp_cnn_xavier_masking_gradient_min_reinit_local_0.
*******
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
/localscratch/esling.40977517.0/env/lib/python3.7/site-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=linear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
[Untrained loss : 85.6381]
[Starting training]
Epoch 0 	 203.658463 	 70.821098 	 72.842583
Epoch 10 	 62.884846 	 59.738102 	 64.889198
Epoch 20 	 51.347115 	 50.119087 	 58.970306
Epoch 30 	 46.581581 	 42.581848 	 43.998596
Epoch 40 	 47.397133 	 43.389492 	 45.089954
Epoch 50 	 43.315037 	 39.773438 	 42.096630
Epoch 60 	 38.109486 	 34.589748 	 36.527637
Epoch 70 	 36.870758 	 37.920696 	 39.216618
Epoch 80 	 34.017937 	 31.369310 	 33.356724
Epoch 90 	 32.256695 	 30.776798 	 32.615658
Epoch 100 	 31.265541 	 29.495422 	 31.516731
Epoch 110 	 32.236629 	 29.934980 	 31.736965
Epoch 120 	 29.521437 	 28.449739 	 30.197725
Epoch 130 	 28.517057 	 27.973906 	 29.490211
Epoch 140 	 27.995861 	 28.063061 	 29.873484
Epoch 150 	 27.186266 	 27.077490 	 28.684404
Epoch 160 	 26.801786 	 26.930588 	 28.532652
Epoch 170 	 26.330847 	 27.093248 	 28.610075
Epoch 180 	 25.263247 	 25.861311 	 27.576342
Epoch 190 	 25.159145 	 26.073381 	 27.663172
Train loss       : 24.873184
Best valid loss  : 25.622459
Best test loss   : 27.668690
Pruning          : 1.00
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : 80.1007]
[Starting training]
Epoch 0 	 77.731567 	 71.961678 	 74.029961
Epoch 10 	 75.785210 	 72.163719 	 74.041756
Epoch 20 	 56.901569 	 54.007648 	 55.659798
Epoch 30 	 55.503399 	 52.900383 	 54.519199
Epoch 40 	 54.359425 	 51.630062 	 53.479313
Epoch 50 	 52.717766 	 52.080486 	 53.633793
Epoch 60 	 51.547550 	 50.856121 	 52.971397
Epoch 70 	 48.932468 	 50.908337 	 52.404766
Epoch 80 	 47.251198 	 50.949627 	 52.459923
Epoch 90 	 45.233826 	 50.989777 	 52.339993
Epoch 100 	 44.174042 	 50.936016 	 52.320976
Epoch 110 	 42.944862 	 50.789078 	 52.156002
Epoch 120 	 42.265816 	 50.922047 	 52.244736
[Model stopped early]
Train loss       : 41.923809
Best valid loss  : 50.417553
Best test loss   : 52.375851
Pruning          : 0.70
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 77.471466 	 72.387825 	 73.998550
Epoch 10 	 76.800865 	 71.718315 	 73.990013
Epoch 20 	 76.803192 	 71.905762 	 73.985352
Epoch 30 	 76.854622 	 72.256813 	 73.986969
Epoch 40 	 76.746239 	 72.009262 	 73.978767
Epoch 50 	 76.800957 	 71.939842 	 73.977943
[Model stopped early]
Train loss       : 76.800957
Best valid loss  : 71.635696
Best test loss   : 73.986206
Pruning          : 0.49
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 79.221687 	 72.387054 	 74.177742
Epoch 10 	 58.461151 	 55.467346 	 56.037975
Epoch 20 	 55.810329 	 53.212749 	 54.047024
Epoch 30 	 54.787189 	 53.239895 	 54.522400
Epoch 40 	 53.766342 	 52.162502 	 53.606968
Epoch 50 	 52.668594 	 52.841274 	 53.781708
Epoch 60 	 50.136494 	 52.334042 	 53.589432
Epoch 70 	 48.378174 	 52.127190 	 53.246517
Epoch 80 	 46.195057 	 52.270294 	 53.372841
Epoch 90 	 44.786427 	 52.251842 	 53.623940
[Model stopped early]
Train loss       : 44.622002
Best valid loss  : 51.404415
Best test loss   : 53.120861
Pruning          : 0.34
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 77.931076 	 72.234589 	 74.098961
Epoch 10 	 76.897705 	 71.913071 	 73.992714
Epoch 20 	 76.846375 	 71.767601 	 73.996765
Epoch 30 	 76.796516 	 72.162926 	 73.999763
Epoch 40 	 76.841530 	 72.583397 	 73.978088
Epoch 50 	 76.669434 	 72.102776 	 73.987076
Epoch 60 	 76.769600 	 71.869003 	 73.976982
Epoch 70 	 76.837196 	 72.137421 	 73.977554
Epoch 80 	 76.865150 	 71.527473 	 73.977753
Epoch 90 	 76.743118 	 72.091728 	 73.975967
Epoch 100 	 76.813637 	 71.871391 	 73.977058
Epoch 110 	 76.751686 	 71.948334 	 73.977242
[Model stopped early]
Train loss       : 76.809692
Best valid loss  : 71.527473
Best test loss   : 73.977753
Pruning          : 0.24
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 80.130592 	 71.733398 	 74.316711
Epoch 10 	 76.852661 	 72.053680 	 74.033180
Epoch 20 	 76.758163 	 71.970917 	 73.990158
Epoch 30 	 76.854050 	 72.009865 	 73.988762
[Model stopped early]
Train loss       : 76.802887
Best valid loss  : 71.733398
Best test loss   : 74.316711
Pruning          : 0.17
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 78.135193 	 72.163773 	 74.152702
Epoch 10 	 76.877502 	 72.282578 	 73.989746
Epoch 20 	 76.830414 	 72.168312 	 73.986679
Epoch 30 	 76.796623 	 72.116226 	 73.984840
Epoch 40 	 76.754997 	 72.235672 	 73.980690
Epoch 50 	 76.831184 	 72.075264 	 73.977425
[Model stopped early]
Train loss       : 76.740082
Best valid loss  : 71.555260
Best test loss   : 73.986824
Pruning          : 0.12
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 79.622009 	 71.866203 	 74.260620
Epoch 10 	 76.752449 	 72.199730 	 74.029579
Epoch 20 	 76.840126 	 72.119682 	 74.006622
Epoch 30 	 76.839317 	 72.128769 	 73.987114
Epoch 40 	 76.846123 	 72.125862 	 73.998184
Epoch 50 	 76.762665 	 72.060005 	 73.977127
[Model stopped early]
Train loss       : 76.795479
Best valid loss  : 71.717690
Best test loss   : 74.005669
Pruning          : 0.08
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 77.616142 	 72.009331 	 74.034653
Epoch 10 	 76.723717 	 71.959679 	 73.992104
Epoch 20 	 76.743500 	 72.014977 	 73.984863
Epoch 30 	 76.870827 	 72.230896 	 73.987877
Epoch 40 	 76.767021 	 72.204498 	 73.976669
Epoch 50 	 76.757820 	 71.872040 	 73.976601
[Model stopped early]
Train loss       : 76.766716
Best valid loss  : 71.495880
Best test loss   : 73.986382
Pruning          : 0.06
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 78.469780 	 71.704445 	 74.195190
Epoch 10 	 76.739525 	 71.873306 	 74.050407
Epoch 20 	 76.873787 	 71.912811 	 73.986153
Epoch 30 	 76.799553 	 72.133499 	 73.987694
Epoch 40 	 76.822403 	 71.881790 	 73.976898
Epoch 50 	 76.814133 	 72.128029 	 73.977905
[Model stopped early]
Train loss       : 76.778648
Best valid loss  : 71.505859
Best test loss   : 73.986588
Pruning          : 0.04
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 78.565575 	 71.874466 	 74.279129
Epoch 10 	 76.801353 	 72.274254 	 73.995438
Epoch 20 	 76.761688 	 72.010338 	 73.990959
Epoch 30 	 76.848747 	 72.091835 	 74.000481
Epoch 40 	 76.661133 	 72.003632 	 73.978653
Epoch 50 	 76.769424 	 72.362686 	 73.979164
Epoch 60 	 76.787315 	 71.834732 	 73.976799
Epoch 70 	 76.724228 	 72.174301 	 73.975754
[Model stopped early]
Train loss       : 76.735161
Best valid loss  : 71.571533
Best test loss   : 73.979652
Pruning          : 0.03
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 78.722221 	 72.542206 	 74.248810
Epoch 10 	 76.877136 	 72.276352 	 73.987190
Epoch 20 	 76.745819 	 71.768654 	 73.991135
Epoch 30 	 76.765282 	 72.033714 	 73.996452
Epoch 40 	 76.894531 	 72.055916 	 73.978836
Epoch 50 	 76.837708 	 72.049065 	 73.977699
[Model stopped early]
Train loss       : 76.809769
Best valid loss  : 71.768654
Best test loss   : 73.991135
Pruning          : 0.02
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 78.829590 	 72.649155 	 74.463051
Epoch 10 	 76.806664 	 72.077217 	 73.987320
Epoch 20 	 76.828140 	 71.482018 	 73.984558
Epoch 30 	 76.715431 	 71.981186 	 73.985176
Epoch 40 	 76.839844 	 71.617760 	 73.980034
Epoch 50 	 76.856407 	 71.754272 	 73.978935
[Model stopped early]
Train loss       : 76.795761
Best valid loss  : 71.482018
Best test loss   : 73.984558
Pruning          : 0.01
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 78.625664 	 72.448860 	 74.316376
Epoch 10 	 76.846939 	 72.066177 	 73.986443
Epoch 20 	 76.839821 	 71.838936 	 73.994339
Epoch 30 	 76.857834 	 71.825584 	 73.992195
Epoch 40 	 76.785294 	 72.054192 	 73.977455
[Model stopped early]
Train loss       : 76.811401
Best valid loss  : 71.664017
Best test loss   : 74.009781
Pruning          : 0.01
[Performing one full cumulative epoch]
0.001
0.001
[Current model size]
================================
Total params      : 4,590,296
--------------------------------
Total memory      : 42.47 MB
Total Flops       : 622.77 MFlops
Total Mem (Read)  : 44.86 MB
Total Mem (Write) : 35.63 MB
[Supermasks testing]
[Untrained loss : nan]
[Starting training]
Epoch 0 	 77.783356 	 72.085022 	 74.094498
Epoch 10 	 76.813606 	 72.082413 	 73.996758
Epoch 20 	 76.766937 	 72.001869 	 73.993164
Epoch 30 	 76.802925 	 72.115623 	 73.989571
Epoch 40 	 76.839394 	 71.947990 	 73.980583
[Model stopped early]
Train loss       : 76.843544
Best valid loss  : 71.587944
Best test loss   : 73.994919
Pruning          : 0.01
