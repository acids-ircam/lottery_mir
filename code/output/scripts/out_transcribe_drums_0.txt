Using base prefix '/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4'
New python executable in /localscratch/esling.41288829.0/env/bin/python
Installing setuptools, pip, wheel...
done.
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already up-to-date: pip in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (19.1.1)
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting scipy (from -r requirements.txt (line 1))
Collecting torch_gpu (from -r requirements.txt (line 2))
Collecting torchvision (from -r requirements.txt (line 3))
Collecting tqdm (from -r requirements.txt (line 4))
Collecting numpy (from -r requirements.txt (line 5))
Collecting matplotlib (from -r requirements.txt (line 6))
Collecting tensorflow_gpu (from -r requirements.txt (line 7))
Collecting pandas (from -r requirements.txt (line 8))
Collecting mpmath (from -r requirements.txt (line 9))
Collecting networkx (from -r requirements.txt (line 10))
Collecting natsort (from -r requirements.txt (line 11))
Collecting joblib (from -r requirements.txt (line 12))
Collecting scikit_learn (from -r requirements.txt (line 13))
Collecting cffi (from -r requirements.txt (line 14))
Collecting pycparser (from -r requirements.txt (line 15))
Collecting audioread (from -r requirements.txt (line 16))
Collecting decorator (from -r requirements.txt (line 17))
Collecting six (from -r requirements.txt (line 18))
Collecting llvmlite (from -r requirements.txt (line 19))
Collecting numba (from -r requirements.txt (line 20))
Collecting imageio (from -r requirements.txt (line 21))
Collecting pillow-simd>=4.1.1 (from torchvision->-r requirements.txt (line 3))
Collecting torch (from torchvision->-r requirements.txt (line 3))
Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 6))
Collecting python-dateutil>=2.1 (from matplotlib->-r requirements.txt (line 6))
Collecting kiwisolver>=1.0.1 (from matplotlib->-r requirements.txt (line 6))
Collecting google-pasta>=0.1.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-preprocessing>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting protobuf>=3.8.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting wrapt>=1.11.1 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting opt-einsum>=2.3.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Requirement already satisfied: wheel>=0.26; python_version >= "3" in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from tensorflow_gpu->-r requirements.txt (line 7)) (0.33.4)
Collecting absl-py>=0.7.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting keras-applications>=1.0.8 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting grpcio>=1.8.6 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting astor>=0.6.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting gast==0.2.2 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting termcolor>=1.1.0 (from tensorflow_gpu->-r requirements.txt (line 7))
Collecting pytz>=2017.2 (from pandas->-r requirements.txt (line 8))
Requirement already satisfied: setuptools in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from numba->-r requirements.txt (line 20)) (41.0.1)
Collecting pillow (from imageio->-r requirements.txt (line 21))
Collecting future (from torch->torchvision->-r requirements.txt (line 3))
Collecting h5py (from keras-applications>=1.0.8->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests<3,>=2.21.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow_gpu->-r requirements.txt (line 7))
Installing collected packages: numpy, scipy, torch-gpu, pillow-simd, future, torch, six, torchvision, tqdm, pyparsing, cycler, python-dateutil, kiwisolver, matplotlib, google-pasta, keras-preprocessing, protobuf, wrapt, opt-einsum, absl-py, h5py, keras-applications, grpcio, astor, urllib3, idna, chardet, certifi, requests, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, werkzeug, markdown, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow-estimator, gast, termcolor, tensorflow-gpu, pytz, pandas, mpmath, decorator, networkx, natsort, joblib, scikit-learn, pycparser, cffi, audioread, llvmlite, numba, pillow, imageio
Successfully installed absl-py-0.7.1 astor-0.8.1 audioread-2.1.6 cachetools-3.1.1 certifi-2020.4.5.1 cffi-1.13.2 chardet-3.0.4 cycler-0.10.0 decorator-4.4.2 future-0.17.1 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 idna-2.9 imageio-2.8.0 joblib-0.14.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 kiwisolver-1.1.0 llvmlite-0.31.0 markdown-3.2 matplotlib-3.2.1 mpmath-1.1.0 natsort-5.3.3 networkx-2.4 numba-0.48.0 numpy-1.18.1 oauthlib-3.1.0 opt-einsum-2.3.2 pandas-1.0.3 pillow-7.0.0 pillow-simd-7.0.0.post3 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 rsa-4.0 scikit-learn-0.22.1 scipy-1.4.1 six-1.14.0 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0 termcolor-1.1.0 torch-1.5.0 torch-gpu-1.0.0 torchvision-0.5.0 tqdm-4.40.2 urllib3-1.25.8 werkzeug-1.0.1 wrapt-1.11.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/nnAudio-0.1.0-py3-none-any.whl
Installing collected packages: nnAudio
Successfully installed nnAudio-0.1.0
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/SoundFile-0.10.3.post1-py2.py3-none-any.whl
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from SoundFile==0.10.3.post1) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from cffi>=1.0->SoundFile==0.10.3.post1) (2.20)
Installing collected packages: SoundFile
Successfully installed SoundFile-0.10.3.post1
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/resampy-0.2.2.tar.gz
Requirement already satisfied: numpy>=1.10 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.18.1)
Requirement already satisfied: scipy>=0.13 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.4.1)
Requirement already satisfied: numba>=0.32 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (0.48.0)
Requirement already satisfied: six>=1.3 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from resampy==0.2.2) (1.14.0)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (0.31.0)
Requirement already satisfied: setuptools in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2) (41.0.1)
Building wheels for collected packages: resampy
  Building wheel for resampy (setup.py): started
  Building wheel for resampy (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/7f/a4/f3/4443d9c0e651405d78bca2bc790f21cb3914c168761d6ce287
Successfully built resampy
Installing collected packages: resampy
Successfully installed resampy-0.2.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/librosa-0.7.2.tar.gz
Requirement already satisfied: audioread>=2.0.0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (2.1.6)
Requirement already satisfied: numpy>=1.15.0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.18.1)
Requirement already satisfied: scipy>=1.0.0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.4.1)
Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.22.1)
Requirement already satisfied: joblib>=0.12 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.14.1)
Requirement already satisfied: decorator>=3.0.0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (4.4.2)
Requirement already satisfied: six>=1.3 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (1.14.0)
Requirement already satisfied: resampy>=0.2.2 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.2.2)
Requirement already satisfied: numba>=0.43.0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.48.0)
Requirement already satisfied: soundfile>=0.9.0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from librosa==0.7.2) (0.10.3.post1)
Requirement already satisfied: setuptools in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (41.0.1)
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)
Requirement already satisfied: cffi>=1.0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.13.2)
Requirement already satisfied: pycparser in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)
Building wheels for collected packages: librosa
  Building wheel for librosa (setup.py): started
  Building wheel for librosa (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/5d/2c/70/9fd1f14d034354cd1109b858bb14d27d56a04a887581ff018b
Successfully built librosa
Installing collected packages: librosa
Successfully installed librosa-0.7.2
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/lmdb-0.98.tar.gz
Building wheels for collected packages: lmdb
  Building wheel for lmdb (setup.py): started
  Building wheel for lmdb (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/46/8c/ac/27ff74457451e040aa411ff52d641111b0a2481c9f8d31ca95
Successfully built lmdb
Installing collected packages: lmdb
Successfully installed lmdb-0.98
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /home/esling/scratch/python_libs/mir_eval-0.6.tar.gz
Requirement already satisfied: numpy>=1.7.0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (1.18.1)
Requirement already satisfied: scipy>=1.0.0 in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (1.4.1)
Requirement already satisfied: future in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (0.17.1)
Requirement already satisfied: six in /localscratch/esling.41288829.0/env/lib/python3.7/site-packages (from mir-eval==0.6) (1.14.0)
Building wheels for collected packages: mir-eval
  Building wheel for mir-eval (setup.py): started
  Building wheel for mir-eval (setup.py): finished with status 'done'
  Stored in directory: /home/esling/.cache/pip/wheels/d1/c4/fe/5455addf1ef19661b1d6285877644eefd17d5aa49a196aa983
Successfully built mir-eval
Installing collected packages: mir-eval
Successfully installed mir-eval-0.6
2020-04-29 04:53:40.730468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-04-29 04:53:40.784381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
*******
Run info.
Optimization will be on cuda.
Model is drums_transcribe_cnn_xavier_trimming_magnitude_reinit_local_0.
*******
[Current model size]
================================
Total params      : 7,597,357
--------------------------------
Total memory      : 21.14 MB
Total Flops       : 2.66 GFlops
Total Mem (Read)  : 45.46 MB
Total Mem (Write) : 16.45 MB
[Supermasks testing]
/localscratch/esling.41288829.0/env/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
[Untrained loss : 0.8942]
[Starting training]
/localscratch/esling.41288829.0/env/lib/python3.7/site-packages/mir_eval/onset.py:51: UserWarning: Estimated onsets are empty.
  warnings.warn("Estimated onsets are empty.")
/localscratch/esling.41288829.0/env/lib/python3.7/site-packages/mir_eval/onset.py:49: UserWarning: Reference onsets are empty.
  warnings.warn("Reference onsets are empty.")
Epoch 0 	 57.402721 	 0.881138 	 0.882383
Epoch 10 	 56.106445 	 0.880137 	 0.882383
Epoch 20 	 56.091938 	 0.879617 	 0.882383
Epoch 30 	 56.085613 	 0.880262 	 0.882383
Epoch 40 	 56.087845 	 0.880855 	 0.882383
Epoch 50 	 56.091938 	 0.879842 	 0.882383
[Model stopped early]
Train loss       : 56.091194
Best valid loss  : 0.878403
Best test loss   : 0.882383
Pruning          : 1.00
0.001
0.001
[Current model size]
================================
Total params      : 5,425,453
--------------------------------
Total memory      : 15.86 MB
Total Flops       : 1.5 GFlops
Total Mem (Read)  : 33.07 MB
Total Mem (Write) : 12.34 MB
[Supermasks testing]
[Untrained loss : 0.8826]
[Starting training]
Epoch 0 	 57.680653 	 0.879469 	 0.882383
Epoch 10 	 56.095657 	 0.880849 	 0.882383
Epoch 20 	 56.102726 	 0.880420 	 0.882383
Epoch 30 	 56.108677 	 0.880597 	 0.882383
Epoch 40 	 56.094170 	 0.880685 	 0.882383
Epoch 50 	 56.103470 	 0.880024 	 0.882383
Epoch 60 	 56.092308 	 0.880721 	 0.882383
[Model stopped early]
Train loss       : 56.092308
Best valid loss  : 0.878682
Best test loss   : 0.882383
Pruning          : 0.75
0.001
0.001
[Current model size]
================================
Total params      : 4,016,941
--------------------------------
Total memory      : 11.90 MB
Total Flops       : 850.78 MFlops
Total Mem (Read)  : 24.62 MB
Total Mem (Write) : 9.26 MB
[Supermasks testing]
[Untrained loss : 0.8928]
[Starting training]
Epoch 0 	 57.568913 	 0.879958 	 0.882383
Epoch 10 	 56.097145 	 0.881582 	 0.882383
Epoch 20 	 56.099377 	 0.880041 	 0.882383
Epoch 30 	 56.101608 	 0.880401 	 0.882383
Epoch 40 	 56.097515 	 0.880275 	 0.882383
Epoch 50 	 56.092682 	 0.880063 	 0.882383
Epoch 60 	 56.114258 	 0.880920 	 0.882383
Epoch 70 	 56.109421 	 0.879870 	 0.882383
Epoch 80 	 56.090820 	 0.881145 	 0.882383
Epoch 90 	 56.077427 	 0.880666 	 0.882383
Epoch 100 	 56.097889 	 0.880490 	 0.882383
[Model stopped early]
Train loss       : 56.112770
Best valid loss  : 0.878757
Best test loss   : 0.882383
Pruning          : 0.56
0.001
0.001
[Current model size]
================================
Total params      : 3,084,541
--------------------------------
Total memory      : 8.93 MB
Total Flops       : 482.74 MFlops
Total Mem (Read)  : 18.75 MB
Total Mem (Write) : 6.95 MB
[Supermasks testing]
[Untrained loss : 0.9074]
[Starting training]
Epoch 0 	 57.630096 	 0.882071 	 0.882383
Epoch 10 	 56.087101 	 0.880555 	 0.882383
Epoch 20 	 56.096027 	 0.880922 	 0.882383
Epoch 30 	 56.078915 	 0.880627 	 0.882383
Epoch 40 	 56.093426 	 0.881667 	 0.882383
Epoch 50 	 56.091938 	 0.880631 	 0.882383
Epoch 60 	 56.104584 	 0.879862 	 0.882383
Epoch 70 	 56.106071 	 0.879478 	 0.882383
[Model stopped early]
Train loss       : 56.095657
Best valid loss  : 0.878773
Best test loss   : 0.882383
Pruning          : 0.42
0.001
0.001
[Current model size]
================================
Total params      : 2,454,982
--------------------------------
Total memory      : 6.70 MB
Total Flops       : 274.77 MFlops
Total Mem (Read)  : 14.61 MB
Total Mem (Write) : 5.21 MB
[Supermasks testing]
[Untrained loss : 0.9040]
[Starting training]
Epoch 0 	 57.581402 	 0.880743 	 0.882383
Epoch 10 	 56.085472 	 0.879819 	 0.882383
Epoch 20 	 55.973366 	 0.855244 	 0.860824
Epoch 30 	 55.979939 	 0.853647 	 0.857554
Epoch 40 	 55.995781 	 0.852198 	 0.854794
Epoch 50 	 55.967686 	 0.854268 	 0.858797
Epoch 60 	 55.969982 	 0.852148 	 0.856145
Epoch 70 	 55.964321 	 0.854743 	 0.858849
Epoch 80 	 55.893654 	 0.850738 	 0.856603
Epoch 90 	 55.830658 	 0.850590 	 0.855223
Epoch 100 	 55.767853 	 0.844722 	 0.850446
Epoch 110 	 55.636963 	 0.835908 	 0.845371
Epoch 120 	 55.618683 	 0.840147 	 0.847919
Epoch 130 	 55.583454 	 0.833165 	 0.842261
Epoch 140 	 55.512428 	 0.835905 	 0.843779
Epoch 150 	 55.469547 	 0.836168 	 0.844415
Epoch 160 	 55.445923 	 0.832498 	 0.842932
[Model stopped early]
Train loss       : 55.449009
Best valid loss  : 0.826046
Best test loss   : 0.838780
Pruning          : 0.32
0.001
0.001
[Current model size]
================================
Total params      : 2,019,736
--------------------------------
Total memory      : 4.97 MB
Total Flops       : 153.36 MFlops
Total Mem (Read)  : 11.61 MB
Total Mem (Write) : 3.87 MB
[Supermasks testing]
[Untrained loss : 0.9003]
[Starting training]
Epoch 0 	 57.575569 	 0.879431 	 0.882383
Epoch 10 	 56.100494 	 0.880235 	 0.882383
Epoch 20 	 56.107563 	 0.881014 	 0.882383
Epoch 30 	 56.094913 	 0.881689 	 0.882383
Epoch 40 	 56.097889 	 0.880328 	 0.882383
Epoch 50 	 56.097515 	 0.879710 	 0.882383
Epoch 60 	 56.099007 	 0.880348 	 0.882383
Epoch 70 	 56.093426 	 0.880024 	 0.882383
[Model stopped early]
Train loss       : 56.091564
Best valid loss  : 0.878695
Best test loss   : 0.882383
Pruning          : 0.24
0.001
0.001
[Current model size]
================================
Total params      : 1,717,038
--------------------------------
Total memory      : 3.73 MB
Total Flops       : 88.24 MFlops
Total Mem (Read)  : 9.49 MB
Total Mem (Write) : 2.9 MB
[Supermasks testing]
[Untrained loss : 0.8994]
[Starting training]
Epoch 0 	 57.622604 	 0.879466 	 0.882383
Epoch 10 	 56.095657 	 0.879625 	 0.882383
Epoch 20 	 56.094170 	 0.880440 	 0.882383
Epoch 30 	 56.096401 	 0.879003 	 0.882383
Epoch 40 	 56.107933 	 0.880424 	 0.882383
Epoch 50 	 56.098633 	 0.879032 	 0.882383
Epoch 60 	 56.104584 	 0.879078 	 0.882383
Epoch 70 	 56.089703 	 0.880126 	 0.882383
[Model stopped early]
Train loss       : 56.106819
Best valid loss  : 0.878050
Best test loss   : 0.882383
Pruning          : 0.18
0.001
0.001
[Current model size]
================================
Total params      : 1,499,950
--------------------------------
Total memory      : 2.74 MB
Total Flops       : 49.12 MFlops
Total Mem (Read)  : 7.89 MB
Total Mem (Write) : 2.13 MB
[Supermasks testing]
[Untrained loss : 0.8877]
[Starting training]
Epoch 0 	 57.663452 	 0.880054 	 0.882383
Epoch 10 	 56.092682 	 0.879912 	 0.882383
Epoch 20 	 56.100494 	 0.880451 	 0.882383
Epoch 30 	 56.104584 	 0.880457 	 0.882383
Epoch 40 	 56.094170 	 0.880180 	 0.882383
Epoch 50 	 56.087845 	 0.881867 	 0.882383
Epoch 60 	 56.096771 	 0.881092 	 0.882383
[Model stopped early]
Train loss       : 56.087471
Best valid loss  : 0.878237
Best test loss   : 0.882383
Pruning          : 0.13
0.001
0.001
[Current model size]
================================
Total params      : 1,346,677
--------------------------------
Total memory      : 2.00 MB
Total Flops       : 27.34 MFlops
Total Mem (Read)  : 6.73 MB
Total Mem (Write) : 1.56 MB
[Supermasks testing]
[Untrained loss : 0.8862]
[Starting training]
Epoch 0 	 57.596745 	 0.880400 	 0.882383
Epoch 10 	 56.098259 	 0.879991 	 0.882383
Epoch 20 	 56.095284 	 0.879792 	 0.882383
Epoch 30 	 56.122070 	 0.880181 	 0.882383
Epoch 40 	 56.094170 	 0.879383 	 0.882383
Epoch 50 	 56.105701 	 0.880298 	 0.882383
[Model stopped early]
Train loss       : 56.088959
Best valid loss  : 0.878737
Best test loss   : 0.882383
Pruning          : 0.10
0.001
0.001
[Current model size]
================================
Total params      : 1,234,585
--------------------------------
Total memory      : 1.50 MB
Total Flops       : 16.41 MFlops
Total Mem (Read)  : 5.92 MB
Total Mem (Write) : 1.17 MB
[Supermasks testing]
[Untrained loss : 0.8836]
[Starting training]
Epoch 0 	 57.779938 	 0.879830 	 0.882383
Epoch 10 	 56.091194 	 0.881332 	 0.882383
Epoch 20 	 56.098633 	 0.879838 	 0.882383
Epoch 30 	 56.099751 	 0.879687 	 0.882383
Epoch 40 	 56.096771 	 0.880132 	 0.882383
Epoch 50 	 56.086357 	 0.880769 	 0.882383
Epoch 60 	 56.104958 	 0.880316 	 0.882383
[Model stopped early]
Train loss       : 56.104958
Best valid loss  : 0.878300
Best test loss   : 0.882383
Pruning          : 0.08
0.001
0.001
[Current model size]
================================
Total params      : 1,154,221
--------------------------------
Total memory      : 1.09 MB
Total Flops       : 9.52 MFlops
Total Mem (Read)  : 5.29 MB
Total Mem (Write) : 870.76 KB
[Supermasks testing]
[Untrained loss : 0.9118]
[Starting training]
Epoch 0 	 57.804142 	 0.879697 	 0.882383
Epoch 10 	 56.112396 	 0.880186 	 0.882383
Epoch 20 	 56.096401 	 0.879728 	 0.882383
Epoch 30 	 56.088215 	 0.880271 	 0.882383
Epoch 40 	 56.100494 	 0.879668 	 0.882383
[Model stopped early]
Train loss       : 56.100494
Best valid loss  : 0.878128
Best test loss   : 0.882383
Pruning          : 0.06
0.001
0.001
[Current model size]
================================
Total params      : 1,092,142
--------------------------------
Total memory      : 0.76 MB
Total Flops       : 5.44 MFlops
Total Mem (Read)  : 4.79 MB
Total Mem (Write) : 607.91 KB
[Supermasks testing]
[Untrained loss : 0.8960]
[Starting training]
Epoch 0 	 57.843796 	 0.880199 	 0.882383
Epoch 10 	 56.106445 	 0.880424 	 0.882383
Epoch 20 	 56.107563 	 0.880521 	 0.882383
Epoch 30 	 56.089333 	 0.880247 	 0.882383
Epoch 40 	 56.091194 	 0.880929 	 0.882383
[Model stopped early]
Train loss       : 56.088959
Best valid loss  : 0.878274
Best test loss   : 0.882383
Pruning          : 0.04
0.001
0.001
[Current model size]
================================
Total params      : 1,047,388
--------------------------------
Total memory      : 0.51 MB
Total Flops       : 3.23 MFlops
Total Mem (Read)  : 4.43 MB
Total Mem (Write) : 410.77 KB
[Supermasks testing]
[Untrained loss : 0.8947]
[Starting training]
Epoch 0 	 57.571636 	 0.879869 	 0.882383
Epoch 10 	 56.093426 	 0.880929 	 0.882383
Epoch 20 	 56.091564 	 0.879930 	 0.882383
Epoch 30 	 56.096401 	 0.880844 	 0.882383
Epoch 40 	 56.104214 	 0.880264 	 0.882383
Epoch 50 	 56.095657 	 0.880219 	 0.882383
Epoch 60 	 56.092308 	 0.878343 	 0.882383
Epoch 70 	 56.099007 	 0.880356 	 0.882383
Epoch 80 	 56.098633 	 0.880555 	 0.882383
Epoch 90 	 56.083008 	 0.880171 	 0.882383
Epoch 100 	 56.079659 	 0.880293 	 0.882383
Epoch 110 	 56.101238 	 0.881076 	 0.882383
[Model stopped early]
Train loss       : 56.084869
Best valid loss  : 0.878226
Best test loss   : 0.882383
Pruning          : 0.03
0.001
0.001
[Current model size]
================================
Total params      : 1,015,320
--------------------------------
Total memory      : 0.35 MB
Total Flops       : 2.15 MFlops
Total Mem (Read)  : 4.18 MB
Total Mem (Write) : 279.34 KB
[Supermasks testing]
[Untrained loss : 0.8903]
[Starting training]
Epoch 0 	 57.763836 	 0.881596 	 0.882383
Epoch 10 	 56.102726 	 0.880808 	 0.882383
Epoch 20 	 56.090820 	 0.879990 	 0.882383
Epoch 30 	 56.104584 	 0.880953 	 0.882383
Epoch 40 	 56.086727 	 0.880041 	 0.882383
Epoch 50 	 56.081520 	 0.880563 	 0.882383
Epoch 60 	 56.100864 	 0.881755 	 0.882383
[Model stopped early]
Train loss       : 56.097145
Best valid loss  : 0.878361
Best test loss   : 0.882383
Pruning          : 0.02
0.001
0.001
[Current model size]
================================
Total params      : 991,581
--------------------------------
Total memory      : 0.26 MB
Total Flops       : 1.72 MFlops
Total Mem (Read)  : 4.03 MB
Total Mem (Write) : 213.57 KB
[Supermasks testing]
[Untrained loss : 0.8875]
[Starting training]
Epoch 0 	 57.581341 	 0.879340 	 0.882383
Epoch 10 	 56.097889 	 0.878510 	 0.882383
Epoch 20 	 56.098633 	 0.879340 	 0.882383
Epoch 30 	 56.110538 	 0.879926 	 0.882383
Epoch 40 	 56.106819 	 0.881384 	 0.882383
[Model stopped early]
Train loss       : 56.101238
Best valid loss  : 0.878510
Best test loss   : 0.882383
Pruning          : 0.02
